# WebSocket 기반 실시간 스트리밍 채팅 시스템

![License](https://img.shields.io/badge/License-MIT-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.103.1-009688.svg)
![WebSocket](https://img.shields.io/badge/WebSocket-Real--time-4DB6AC.svg)
![Python](https://img.shields.io/badge/Python-3.9+-3776AB.svg)
![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4-412991.svg)

## 프로젝트 개요

본 프로젝트는 WebSocket 기술을 활용한 고성능 실시간 스트리밍 채팅 시스템으로, 대규모 동시 접속과 실시간 메시지 처리를 지원하는 확장 가능한 아키텍처를 구현했습니다. 유튜브 라이브 채팅처럼 여러 사용자가 실시간으로 소통할 수 있는 환경을 제공하며, AI 기반 대화 기능을 통합했습니다.

## 기술 스택

### 백엔드
- **FastAPI**: 비동기 처리 기반의 고성능 웹 프레임워크
- **WebSocket**: 실시간 양방향 통신 프로토콜
- **SQLAlchemy**: ORM(Object-Relational Mapping) 라이브러리
- **Alembic**: 데이터베이스 마이그레이션 도구
- **Bcrypt**: 보안 해싱 알고리즘

### 프론트엔드
- **HTML5 / CSS3 / JavaScript**: 웹 표준 기술
- **Bootstrap**: 반응형 UI 프레임워크
- **Jinja2**: 서버 사이드 템플릿 엔진

### 인공지능 및 외부 서비스
- **OpenAI API**: GPT 모델 통합으로 AI 채팅 기능 구현

### 시스템 운영
- **Locust**: 부하 테스트 및 성능 분석
- **Redis**: 메시지 캐싱 및 WebSocket 브로드캐스팅 최적화 (선택적)

## 주요 기능

### 실시간 채팅 시스템
- **WebSocket 기반 실시간 통신**: 지연 시간을 최소화한 양방향 통신 구현
- **채팅방 관리**: 다중 채팅방 생성 및 참여자 관리
- **메시지 스트리밍**: 대용량 트래픽 환경에서도 원활한 메시지 전송 지원
- **자동 재연결**: 네트워크 불안정 상황에서 WebSocket 연결 복구 메커니즘

### 사용자 관리
- **계정 시스템**: 회원가입, 로그인 및 사용자 인증 구현
- **권한 관리**: 관리자/일반 사용자 역할 구분
- **보안 처리**: 사용자 비밀번호 bcrypt 해싱 및 데이터 보안

### AI 기반 대화 기능
- **OpenAI GPT 통합**: 자연어 처리 기반의 지능형 대화 기능
- **AI 채팅방**: 사용자와 AI 간의 전용 대화 공간
- **스트리밍 응답**: AI 응답을 실시간으로 스트리밍하여 사용자 경험 향상

### 성능 최적화
- **샤딩 아키텍처**: 대규모 사용자 처리를 위한 연결 분산
- **메시지 큐잉**: 대량 메시지 처리를 위한 비동기 큐 시스템
- **배치 프로세싱**: 브로드캐스팅 최적화를 위한 메시지 배치 처리

### 모니터링 및 분석
- **실시간 통계**: 채팅방 활동, 사용자 참여도, 시스템 성능 측정
- **부하 테스트**: Locust를 활용한 동시 접속 및 메시지 처리 성능 분석
- **시스템 모니터링**: 자원 사용량 및 성능 지표 수집

## 시스템 아키텍처

```
┌─────────────────┐      ┌─────────────────┐      ┌─────────────────┐
│                 │      │                 │      │                 │
│  클라이언트      │◄────►│  WebSocket 서버  │◄────►│  데이터베이스     │
│  (브라우저)      │      │  (FastAPI)      │      │  (SQLite)       │
│                 │      │                 │      │                 │
└─────────────────┘      └───────┬─────────┘      └─────────────────┘
                                 │
                                 ▼
                         ┌─────────────────┐
                         │                 │
                         │   AI 서비스      │
                         │  (OpenAI API)   │
                         │                 │
                         └─────────────────┘
```

## 구현 상세

### 연결 관리 최적화
- **Weak Reference**: 메모리 누수 방지를 위한 참조 관리
- **샤딩 기법**: 사용자 ID 기반 샤딩으로 연결 분산
- **비동기 처리**: 이벤트 루프 블로킹 방지 아키텍처

### 메시지 처리 파이프라인
1. 클라이언트 메시지 수신 (WebSocket)
2. 메시지 유효성 검증 및 처리
3. 데이터베이스 저장
4. 샤드별 메시지 큐 분배
5. 배치 프로세싱 후 브로드캐스트
6. 클라이언트 전송 (비동기)


## 설치 및 실행 방법

### 필수 요구사항
- Python 3.9 이상
- 가상 환경 관리자 (venv, conda 등)
- OpenAI API 키 (AI 채팅 기능 사용 시)

### 설치 과정

1. 저장소 클론 및 디렉토리 이동
```bash
git clone https://github.com/yourusername/realtime-chat-system.git
cd realtime-chat-system
```

2. 가상환경 생성 및 활성화
```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate
```

3. 의존성 패키지 설치
```bash
pip install -r requirements.txt
```

4. 환경 변수 설정
- `.env` 파일 생성 후 필요한 환경 변수 설정
```
OPENAI_API_KEY=your_api_key_here
```

5. 데이터베이스 초기화 및 관리자 계정 생성
```bash
python init_admin.py
```

### 실행 방법

#### 개발 모드
```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

#### 프로덕션 모드
```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

#### 부하 테스트
```bash
locust -f locustfile.py
```

## 성능 및 확장성

현재 구현된 시스템에서 예상되는 성능 지표입니다:

- **동시 접속**: 단일 서버에서 200~300명의 동시 접속자 안정적 처리 가능
- **메시지 처리량**: 초당 50~100개 메시지 처리 (SQLite 데이터베이스 기준)
- **응답 시간**: 
  - 일반 메시지: 평균 100~200ms 응답 시간
  - AI 응답 메시지: 외부 API 응답 시간에 따라 500ms~2초
- **확장성**: 
  - 샤딩 구현으로 단일 서버 내 연결 관리 최적화
  - Redis 통합 시 다중 서버 환경으로 확장 가능성 있음
  - 현재 SQLite 사용으로 쓰기 작업에 병목 현상 발생 가능성 있음

시스템 확장을 위해 다음과 같은 업그레이드가 필요합니다:
- SQLite에서 PostgreSQL과 같은 RDBMS로 마이그레이션
- Redis를 활용한 세션 및 메시지 캐싱 구현
- 부하 분산을 위한 로드 밸런서 도입

## 향후 개선 계획

- **클라이언트 측 최적화**: 메시지 버퍼링, 리소스 캐싱, DOM 업데이트 최적화
- **WebRTC 통합**: 음성/영상 채팅 기능 추가
- **실시간 AI 모델 통합**: 더 다양한 AI 모델 및 기능 지원
- **End-to-End 암호화**: 메시지 보안 강화
- **분산 캐싱**: Redis 기반 캐싱 계층 구현
- **마이크로서비스 아키텍처**: 기능별 서비스 분리와 API 게이트웨이 도입



## 라이선스

이 프로젝트는 MIT 라이선스를 따릅니다. 자세한 내용은 LICENSE 파일을 참조하세요. 