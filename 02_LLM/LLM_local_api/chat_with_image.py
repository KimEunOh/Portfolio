import os
from pathlib import Path
from typing import List, Optional, Dict, Generator, AsyncGenerator, Union, Tuple, Any
from fastapi import FastAPI, Request, Form
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, StreamingResponse
import uvicorn
import requests
import json
import time
from dotenv import load_dotenv
from retriever import retrieve_from_local_file
import base64
from PIL import Image
from io import BytesIO
import re
import asyncio
from prometheus_client import Gauge, Counter, Histogram, start_http_server
from prometheus_server import PrometheusServer  # 모듈 임포트

# 예시: vLLM 서버에서 제공하는 특정 메트릭을 로컬 Prometheus로 옮기는 용도
VLLM_ACTIVE_SESSIONS = Gauge(
    "vllm_active_sessions", "Number of active sessions in vLLM server"
)
VLLM_TOTAL_TOKENS = Counter(
    "vllm_total_tokens_generated", "Total tokens generated by vLLM"
)

# 이미 정의된 REQUEST_COUNT, LATENCY_HIST 등이 있다고 가정
REQUEST_COUNT = Counter("vllm_request_count", "Number of requests processed")
LATENCY_HIST = Histogram(
    "vllm_inference_latency_seconds", "Inference latency histogram"
)


app = FastAPI()
templates = Jinja2Templates(directory="templates")
app.mount("/static", StaticFiles(directory="static"), name="static")

# 전역 변수로 봇 인스턴스 캐시
bot_instance = None

# Prometheus 서버 인스턴스 (전역 변수)
prometheus_server = None

# 환경변수에서 Prometheus URL 가져오기 (Docker 컨테이너 간 통신용)
prometheus_url = os.getenv("PROMETHEUS_URL", "http://localhost:9090")

vllm_host = "https://mmxoelfz0q6gnk-8000.proxy.runpod.net"
vllm_url = f"{vllm_host}/generate"
vllm_metrics_url = f"{vllm_host}/metrics"


class ImageRAGChatBot:
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key
        self.retriever = None
        self.system_message = """
        당신은 제공된 문서 컨텍스트를 기반으로 정확한 답변을 제공하는 도우미입니다.
        질문에 대해 답변할 때 반드시 제공된 컨텍스트에 있는 정보를 사용하세요.
        관련 정보가 없는 경우, "제공된 문서에서 관련 정보를 찾을 수 없습니다"라고 명시하세요.
        컨텍스트의 출처를 인용하여 답변의 신뢰성을 높이세요. (예: "SalesUP 관리자 사용가이드, 페이지 10에 따르면...")
        답변할 때는 구체적이고 정확하게 관련 정보를 포함시켜야 합니다.
        모든 답변은 한국어로만 제공하세요.
        질문과 관련 없는 일반적인 정보를 추가하지 마세요.
        """
        self.retrievers = []  # 여러 문서별 검색기를 저장하는 리스트

    def load_knowledge_base(self, folder_path: str) -> None:
        try:
            folder = Path(folder_path)
            if not folder.exists():
                raise FileNotFoundError(f"폴더를 찾을 수 없습니다: {folder_path}")

            pdf_files = list(folder.glob("*.pdf"))
            if not pdf_files:
                raise FileNotFoundError(f"폴더에 PDF 파일이 없습니다: {folder_path}")

            print(f"문서 로드 시작. 총 {len(pdf_files)}개 파일 처리 예정...")

            # 환경 변수에서 위험한 역직렬화 허용 옵션 확인
            allow_dangerous = os.getenv(
                "ALLOW_DANGEROUS_DESERIALIZATION", "False"
            ).lower() in ("true", "1", "yes")
            if allow_dangerous:
                print(
                    "경고: 위험한 역직렬화가 허용됩니다. 신뢰할 수 있는 소스의 데이터만 사용하세요."
                )

            # 각 파일에 대한 개별 리트리버 생성
            for pdf_file in pdf_files:
                try:
                    print(f"파일 로드 중: {pdf_file.name}")
                    retriever = retrieve_from_local_file(str(pdf_file))
                    self.retrievers.append(
                        {"file_name": pdf_file.name, "retriever": retriever}
                    )
                    print(f"✅ {pdf_file.name} 로드 완료")
                except Exception as e:
                    print(f"❌ {pdf_file.name} 로드 실패: {str(e)}")
                    continue

            print(f"지식 베이스 로드 완료. 총 {len(self.retrievers)}개 문서 처리됨")

        except Exception as e:
            print(f"지식 베이스 로드 중 오류 발생: {str(e)}")
            import traceback

            traceback.print_exc()

    def _get_relevant_context(self, query: str) -> Dict:
        if not self.retrievers:
            return {"text": "", "images": []}

        try:
            all_documents = []
            all_image_data = []

            # 각 문서별 검색 결과 수집
            for retriever_data in self.retrievers:
                try:
                    file_name = retriever_data["file_name"]
                    retriever = retriever_data["retriever"]

                    # 최신 LangChain API 호환성 유지
                    try:
                        docs = retriever.invoke(query, config={"k": 2})
                    except (AttributeError, TypeError):
                        docs = retriever.get_relevant_documents(query, k=2)

                    if docs:
                        all_documents.extend(docs)

                        # 이미지 추출 로직
                        for doc in docs:
                            try:
                                pdf_images = self._extract_images_from_pdf(
                                    doc.metadata.get("source", ""),
                                    doc.metadata.get("page", 1),
                                )
                                for img_data in pdf_images:
                                    all_image_data.append(
                                        {
                                            "data": img_data,
                                            "source": file_name,
                                            "page": doc.metadata.get("page", "Unknown"),
                                        }
                                    )
                            except Exception as img_err:
                                print(f"이미지 추출 오류 ({file_name}): {str(img_err)}")
                except Exception as doc_err:
                    print(
                        f"문서 검색 오류 ({retriever_data.get('file_name', 'Unknown')}): {str(doc_err)}"
                    )

            # 관련성 기준으로 정렬 (향후 구현)

            # 상위 3개 문서만 컨텍스트로 포함
            top_documents = (
                all_documents[:3] if len(all_documents) > 3 else all_documents
            )

            # 컨텍스트 포맷팅
            context_parts = []
            for doc in top_documents:
                source = doc.metadata.get("source", "Unknown source")
                page = doc.metadata.get("page", "Unknown page")

                # 파일 경로에서 파일명만 추출
                file_name = (
                    source.split("/")[-1]
                    if "/" in source
                    else source.split("\\")[-1] if "\\" in source else source
                )

                # 컨텍스트 추가 - 출처 정보를 명확하게 포함
                context_parts.append(
                    f"[출처: {file_name}, 페이지: {page}]\n{doc.page_content}"
                )

            return {"text": "\n\n".join(context_parts), "images": all_image_data}
        except Exception as e:
            print(f"컨텍스트 검색 중 오류 발생: {str(e)}")
            import traceback

            traceback.print_exc()
            return {"text": "", "images": []}

    def _extract_images_from_pdf(self, pdf_path: str, page_number: int) -> List[str]:
        """PDF 페이지에서 이미지를 추출하고 base64로 인코딩"""
        try:
            from pdf2image import convert_from_path

            images = convert_from_path(
                pdf_path, first_page=page_number, last_page=page_number
            )
            result = []
            for img in images:
                buffered = BytesIO()
                img.save(buffered, format="PNG")
                img_str = base64.b64encode(buffered.getvalue()).decode()
                result.append(img_str)
            return result
        except Exception as e:
            print(f"PDF 이미지 추출 오류: {str(e)}")
            return []

    def _clean_text(self, text: str, full_cleaning: bool = False) -> str:
        """텍스트 정리를 위한 공통 함수"""
        try:
            if not isinstance(text, str):
                if isinstance(text, list):
                    text = "".join([str(item) for item in text])
                else:
                    text = str(text) if text is not None else ""

            # 기본 정리 작업
            text = re.sub(r"\[INST\].*?\[/INST\]", "", text, flags=re.DOTALL)
            text = text.replace("<s>", "").replace("</s>", "")
            text = re.sub(r"\s*\[/INST\]\s*$", "", text)
            text = text.strip()

            # 전체 응답 정리가 필요한 경우 추가 작업 수행
            if full_cleaning:
                # 컨텍스트 정보 제거
                text = re.sub(
                    r"다음은.*?정보입니다:.*?(?=\n\n|$)", "", text, flags=re.DOTALL
                )
                # 이미지 설명 제거
                text = re.sub(r"이미지 \d+:.*?(?=\n\n|$)", "", text, flags=re.DOTALL)
                # 출처 인용 형식 정리
                text = re.sub(r"\[출처:.*?페이지:.*?\]", "", text)
                # 불필요한 공백 및 줄바꿈 정리
                text = re.sub(r"\n\s*\n", "\n\n", text)
                text = re.sub(r"\n{3,}", "\n\n", text)
                text = re.sub(r"^\s+", "", text, flags=re.MULTILINE)
                text = re.sub(r"\s+$", "", text, flags=re.MULTILINE)
                text = re.sub(r"\s+", " ", text)

            return text
        except Exception as e:
            print(f"텍스트 정리 중 오류 발생: {str(e)}")
            return str(text) if text else ""

    def _process_stream_chunk(self, chunk: str) -> str:
        """스트리밍 청크 처리 및 정리"""
        return self._clean_text(chunk)

    def _clean_response_text(self, text: str) -> str:
        """전체 응답 텍스트 정리"""
        return self._clean_text(text, full_cleaning=True)

    def _prepare_prompt_data(self, prompt: str) -> Tuple[Dict, Dict, List[Dict]]:
        """프롬프트 처리 및 컨텍스트 데이터 준비를 위한 공통 함수"""
        context_data = self._get_relevant_context(prompt)
        augmented_prompt = self._create_augmented_prompt(prompt, context_data)

        # 이미지 처리를 위한 텍스트 설명 추가
        image_descriptions = []
        if context_data["images"]:
            for i, img in enumerate(context_data["images"]):
                image_descriptions.append(
                    f"이미지 {i+1}: 문서 {img['source']}, 페이지 {img['page']}의 이미지가 있습니다."
                )

        image_text = "\n".join(image_descriptions)
        prompt_with_images = (
            f"{augmented_prompt['text']}\n\n{image_text}"
            if image_text
            else augmented_prompt["text"]
        )

        # API 요청을 위한 페이로드 생성
        payload = {
            "prompt": f"<s>[INST] {self.system_message} [/INST]\n\n[INST] {prompt_with_images} [/INST]",
            "temperature": 0.0,
            "max_tokens": 1024,
            "stop": ["<|eot_id|>", "<|eom_id|>", "[/INST]"],
        }

        sources = self._extract_sources(context_data["text"])

        return context_data, payload, sources

    def _extract_response_text(self, data: Dict) -> str:
        """다양한 API 응답 형식에서 텍스트 추출"""
        if "text" in data:
            return data["text"]
        elif "outputs" in data and len(data["outputs"]) > 0:
            output = data["outputs"][0]
            if isinstance(output, dict) and "text" in output:
                return output["text"]
            elif isinstance(output, str):
                return output
        elif "choices" in data and len(data["choices"]) > 0:
            choice = data["choices"][0]
            if isinstance(choice, dict):
                if "text" in choice:
                    return choice["text"]
                elif "delta" in choice and "content" in choice["delta"]:
                    return choice["delta"]["content"]
        return ""

    def _create_fallback_response(
        self, context_data: Dict, sources: List[Dict], error_msg: Optional[str] = None
    ) -> Dict:
        """오류 발생 시 기본 응답 생성"""
        fallback_text = "현재 AI 모델에 연결할 수 없습니다. 다음은 관련 문서에서 찾은 정보입니다:\n\n"
        if context_data.get("text"):
            fallback_text += context_data["text"]
        else:
            fallback_text += "관련 정보를 찾지 못했습니다."

        if error_msg:
            print(f"오류 발생: {error_msg}")

        return {
            "text": fallback_text,
            "full_text": fallback_text,
            "images": context_data.get("images", []),
            "sources": sources,
            "done": True,
        }

    def get_streaming_response(self, prompt: str) -> Generator[Dict, None, None]:
        """스트리밍 응답을 제공하는 제너레이터 함수"""
        REQUEST_COUNT.inc()
        start_t = time.time()

        try:
            # 공통 프롬프트 데이터 준비
            context_data, payload, sources = self._prepare_prompt_data(prompt)

            # 스트리밍 모드 활성화
            payload["stream"] = True

            # 응답 누적을 위한 변수
            full_response = ""
            previously_processed_text = ""

            try:
                # 서버 API가 지원하는 스트리밍 응답 형식에 따라 처리
                print("스트리밍 응답 처리 시작")

                stream_start = time.time()

                with requests.post(
                    vllm_url, json=payload, timeout=60, stream=True
                ) as response:
                    response.raise_for_status()  # HTTP 오류 확인

                    # 응답 형식 확인을 위한 디버깅 로그
                    content_type = response.headers.get("content-type", "")
                    print(f"응답 Content-Type: {content_type}")

                    for line in response.iter_lines():
                        if not line:
                            continue

                        # 바이트를 문자열로 디코딩
                        try:
                            line_text = line.decode("utf-8")
                        except UnicodeDecodeError as e:
                            print(f"디코딩 오류: {e}")
                            continue

                        # SSE 형식 처리 ('data:' 접두어)
                        if line_text.startswith("data:"):
                            line_text = line_text[5:].strip()

                        # [DONE] 메시지 처리
                        if line_text == "[DONE]":
                            print("스트림 종료 ([DONE] 수신)")
                            continue

                        # 빈 라인 스킵
                        if not line_text:
                            continue

                        try:
                            # JSON 파싱
                            data = json.loads(line_text)

                            # 다양한 응답 형식에서 텍스트 추출
                            chunk_text = self._extract_response_text(data)

                            if isinstance(chunk_text, list):
                                chunk_text = "".join(str(item) for item in chunk_text)

                            # 청크가 없으면 다음 반복으로
                            if not chunk_text:
                                print("청크에 텍스트가 없음, 스킵")
                                continue

                            # 중복 청크 방지를 위한 차이점 추출
                            if (
                                chunk_text.startswith(previously_processed_text)
                                and len(previously_processed_text) > 0
                            ):
                                # 이전에 처리한 부분을 제외하고 새 부분만 사용
                                new_chunk = chunk_text[len(previously_processed_text) :]
                                previously_processed_text = chunk_text  # 전체 업데이트
                            else:
                                # 완전히 새로운 청크
                                new_chunk = chunk_text
                                previously_processed_text = chunk_text

                            # 빈 청크 스킵
                            if not new_chunk.strip():
                                continue

                            # 청크 정리
                            cleaned_chunk = self._process_stream_chunk(new_chunk)

                            # 응답 누적
                            full_response += cleaned_chunk

                            # 응답 객체 생성 및 반환
                            yield {
                                "text": cleaned_chunk,
                                "full_text": full_response,
                                "images": context_data["images"],
                                "sources": sources,
                                "done": False,
                            }
                        except json.JSONDecodeError as je:
                            print(
                                f"JSON 디코딩 오류: {je}, 원시 데이터: {line_text[:50]}..."
                            )
                            continue
                        except Exception as e:
                            print(f"청크 처리 중 오류: {str(e)}")
                            continue

                # 스트리밍 종료 - 최종 응답 반환
                stream_end = time.time()
                print(f"스트리밍 처리 시간: {stream_end - stream_start:.2f}초")
                yield {
                    "text": "",
                    "full_text": full_response,
                    "images": context_data["images"],
                    "sources": sources,
                    "done": True,
                }

            except requests.exceptions.RequestException as e:
                # 오류 발생 시 기본 응답 생성 및 반환
                yield self._create_fallback_response(context_data, sources, str(e))

            # 지연 시간 측정
            LATENCY_HIST.observe(time.time() - start_t)

        except Exception as e:
            error_msg = f"스트리밍 응답 생성 중 오류 발생: {str(e)}"
            print(error_msg)
            yield {
                "text": error_msg,
                "full_text": error_msg,
                "images": [],
                "sources": [],
                "done": True,
            }

    def get_response(
        self, prompt: str, stream: bool = False
    ) -> Union[Generator[Dict, None, None], Dict]:
        """프롬프트에 대한 응답을 생성 (스트림 또는 일반 모드)"""

        REQUEST_COUNT.inc()
        # (실제 지연 시간 측정을 위해) 모니터링 시작
        start_t = time.time()
        if stream:
            # 스트리밍 모드에서는 제너레이터 반환
            return self.get_streaming_response(prompt)

        try:
            # 공통 프롬프트 데이터 준비
            context_data, payload, sources = self._prepare_prompt_data(prompt)

            try:
                # vllm API 호출
                response = requests.post(vllm_url, json=payload, timeout=60)
                data = json.loads(response.content)

                # 응답 텍스트 추출
                raw_response_text = self._extract_response_text(data)
                if not raw_response_text:
                    raw_response_text = "응답을 받을 수 없습니다."

                # 응답 텍스트 정리
                cleaned_response = self._clean_response_text(raw_response_text)

                # 응답 구조화
                return {
                    "text": cleaned_response,
                    "images": context_data["images"],
                    "sources": sources,
                }
            except requests.exceptions.RequestException as e:
                # 오류 발생 시 기본 응답 반환
                fallback = self._create_fallback_response(context_data, sources, str(e))
                return {
                    "text": fallback["full_text"],
                    "images": fallback["images"],
                    "sources": fallback["sources"],
                }
        except Exception as e:
            error_msg = f"응답 생성 중 오류 발생: {str(e)}"
            print(error_msg)
            return {"text": error_msg, "images": [], "sources": []}

    def _create_augmented_prompt(self, prompt: str, context_data: Dict) -> Dict:
        if context_data["text"]:
            return {
                "text": f"""
                다음은 여러 문서에서 가져온 컨텍스트 정보입니다:
                {context_data['text']}

                위의 컨텍스트와 제공된 이미지를 바탕으로 다음 질문에 답변해주세요:
                {prompt}
                
                컨텍스트에서 정보를 제공할 때 출처를 인용해주세요.
                반드시 한국어로만 응답해주세요.
                """
            }
        return {"text": prompt}

    def _extract_sources(self, context_text: str) -> List[Dict]:
        """컨텍스트에서 출처 정보를 추출합니다."""
        sources = []
        try:
            # [출처: 파일명, 페이지: 번호] 형식의 패턴 매칭
            pattern = r"\[출처: (.*?), 페이지: (.*?)\]"
            matches = re.finditer(pattern, context_text)

            for match in matches:
                source = {"file": match.group(1), "page": match.group(2)}
                if source not in sources:  # 중복 제거
                    sources.append(source)
        except Exception as e:
            print(f"출처 추출 중 오류 발생: {str(e)}")
        return sources


# 봇 인스턴스 초기화 함수
def initialize_bot(force_reload=False):
    global bot_instance

    # 이미 인스턴스가 있고 강제 재로드가 아니면 기존 인스턴스 반환
    if bot_instance is not None and not force_reload:
        return bot_instance

    # 환경 변수 로드
    load_dotenv()

    # API 키 확인
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEY 환경 변수가 설정되지 않았습니다.")

    # 봇 인스턴스 생성
    bot_instance = ImageRAGChatBot(api_key=api_key)

    # 문서 폴더에서 문서 로드
    documents_dir = os.path.join(
        os.path.dirname(os.path.abspath(__file__)), "documents"
    )
    print(f"문서 디렉토리 경로: {documents_dir}")

    if os.path.exists(documents_dir):
        print(f"문서 디렉토리 '{documents_dir}'에서 문서 로드 시작...")
        bot_instance.load_knowledge_base(documents_dir)
        print("문서 로드 완료!")
    else:
        print(f"경고: 문서 디렉토리 '{documents_dir}'를 찾을 수 없습니다.")

    return bot_instance


# FastAPI 라우트
@app.get("/", response_class=HTMLResponse)
async def read_root(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})


@app.post("/chat")
async def chat(prompt: str = Form(...), stream: bool = Form(False)):
    # 봇 인스턴스 초기화
    initialize_bot()

    if stream:
        # 스트리밍 응답을 위한 비동기 제너레이터
        async def stream_response():
            generator = bot_instance.get_response(prompt, stream=True)
            for chunk in generator:
                yield f"data: {json.dumps(chunk)}\n\n"

        return StreamingResponse(stream_response(), media_type="text/event-stream")
    else:
        # 일반 응답
        response = bot_instance.get_response(prompt, stream=False)
    return response


# 서버 시작 시 초기화 함수 (수정됨)
@app.on_event("startup")
async def startup_event():
    global prometheus_server

    # 봇 인스턴스 초기화
    initialize_bot(force_reload=True)

    # vLLM 메트릭 스크래핑 태스크 시작
    loop = asyncio.get_running_loop()
    loop.create_task(vllm_scrape_loop())

    # Prometheus 서버 인스턴스 생성 및 설정 파일 사용
    try:
        # Prometheus 경로 확인 - 없으면 None 전달
        prometheus_server = PrometheusServer(port=9090)

        # 설정 파일 경로
        config_path = os.path.join(os.path.dirname(__file__), "prometheus_config.yml")

        # 설정 파일이 존재하면 로드
        if os.path.exists(config_path):
            import yaml

            with open(config_path, "r") as f:
                config = yaml.safe_load(f)
                prometheus_server.add_scrape_config(config)
        else:
            # 설정 파일이 없으면 기본값 사용
            prometheus_server.set_default_configs(
                metrics_exporter_port=8080,
                vllm_host=vllm_host.replace("https://", "").replace("http://", ""),
            )

        # 서버 시작 (실패해도 계속 진행)
        server_started = prometheus_server.start()
        if not server_started:
            print(
                "Prometheus 서버를 시작할 수 없습니다. 메트릭 내보내기만 활성화합니다."
            )
    except Exception as e:
        print(f"Prometheus 서버 설정 중 오류 발생: {e}")
        print("Prometheus 서버 없이 계속 진행합니다.")


# 서버 종료 시 정리 함수 추가
@app.on_event("shutdown")
async def shutdown_event():
    global prometheus_server

    # Prometheus 서버 종료
    if prometheus_server:
        prometheus_server.stop()


# -----------------------------------------------------------
# vLLM 서버 메트릭 주기적 스크레이핑 로직 (예시)
# -----------------------------------------------------------


async def vllm_scrape_loop():
    """
    vllm_host/metrics 엔드포인트에 접근하여 메트릭을 파싱,
    로컬 Prometheus 메트릭(VLLM_ACTIVE_SESSIONS, VLLM_TOTAL_TOKENS 등)에 반영
    """
    while True:
        try:
            resp = requests.get(vllm_metrics_url, timeout=5)
            if resp.status_code == 200:
                metrics_text = resp.text
                # vLLM 메트릭 포맷(plaintext)을 라인 단위로 분석
                # 아래는 예시로 "vllm_active_sessions" 또는 "vllm_total_tokens_generated" 같은 이름을 찾아서
                # 값만 파싱해 로컬에 업데이트하는 예시입니다.

                for line in metrics_text.split("\n"):
                    # 예: vllm_active_sessions 12
                    if line.startswith("vllm_active_sessions"):
                        try:
                            parts = line.split()
                            val = float(parts[1])
                            VLLM_ACTIVE_SESSIONS.set(val)
                        except:
                            continue

                    # 예: vllm_total_tokens_generated 12345
                    if line.startswith("vllm_total_tokens_generated"):
                        try:
                            parts = line.split()
                            val = float(parts[1])
                            # Counter는 set이 아닌 inc(증가) 개념이므로
                            # vLLM 측 total_tokens를 계속 누적한다고 가정
                            # 만약 누적값이 아니라 순간값이면 로직을 달리해야 함
                            VLLM_TOTAL_TOKENS.inc(val)
                        except:
                            continue

            else:
                print(f"[vllm_scrape_loop] vLLM 메트릭 요청 실패: {resp.status_code}")
        except Exception as e:
            print(f"[vllm_scrape_loop] 예외 발생: {e}")

        # 10초에 한 번씩 스크레이핑
        await asyncio.sleep(10)


if __name__ == "__main__":
    # Prometheus Exporter 시작 (메트릭 노출)
    start_http_server(8080)

    # FastAPI 서버 시작
    uvicorn.run(app, host="0.0.0.0", port=8000)
