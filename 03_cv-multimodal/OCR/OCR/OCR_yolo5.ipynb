{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\keo\\keo\\ntoday\\salesUP\\yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "c:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ntoday-mK10C09h-py3.12\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5.git\n",
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from -r requirements.txt (line 7)) (1.26.4)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from -r requirements.txt (line 8)) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=10.3.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from -r requirements.txt (line 9)) (10.4.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from -r requirements.txt (line 10)) (6.1.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from -r requirements.txt (line 11)) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from -r requirements.txt (line 12)) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from -r requirements.txt (line 13)) (1.14.1)\n",
      "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from -r requirements.txt (line 15)) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from -r requirements.txt (line 16)) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from -r requirements.txt (line 17)) (4.67.1)\n",
      "Requirement already satisfied: ultralytics>=8.2.34 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from -r requirements.txt (line 18)) (8.3.74)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from -r requirements.txt (line 27)) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
      "Requirement already satisfied: setuptools>=70.0.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from -r requirements.txt (line 42)) (75.6.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2024.12.14)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from tqdm>=4.66.3->-r requirements.txt (line 17)) (0.4.6)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (2.0.14)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.2)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.2)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, gitdb, thop, gitpython\n",
      "Successfully installed gitdb-4.0.12 gitpython-3.1.44 smmap-5.0.2 thop-0.1.1.post2209072238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# YOLOv5 실행 경로 설정\n",
    "yolo_path = \"yolo5\"  # YOLOv5가 저장된 경로\n",
    "weights_path = (\n",
    "    r\"C:/keo/keo/ntoday/salesUP/yolo5/runs/train/keo_yolov5s_results/weights/best.pt\"\n",
    ")\n",
    "\n",
    "source_folder = \"image/\"  # 입력 이미지 폴더\n",
    "\n",
    "# YOLOv5 실행 명령어\n",
    "command = f\"python {yolo_path}/detect.py --weights {weights_path} --conf 0.5 --source image/KakaoTalk_20250210_145938006_01.jpg\"\n",
    "\n",
    "# 명령어 실행\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['C:\\\\\\\\keo\\\\\\\\keo\\\\\\\\ntoday\\\\\\\\salesUP\\\\\\\\yolov5\\\\\\\\runs\\\\\\\\train\\\\\\\\keoyolov5sresults\\\\\\\\weights\\\\\\\\best.pt'], source=image/KakaoTalk_20250210_145938006_01.jpg, data=yolov5\\data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_format=0, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5\\runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5  v7.0-398-g5cdad892 Python-3.12.6 torch-2.6.0+cpu CPU\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\keo\\keo\\ntoday\\salesUP\\yolov5\\detect.py\", line 438, in <module>\n",
      "    main(opt)\n",
      "  File \"c:\\keo\\keo\\ntoday\\salesUP\\yolov5\\detect.py\", line 433, in main\n",
      "    run(**vars(opt))\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ntoday-mK10C09h-py3.12\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\keo\\keo\\ntoday\\salesUP\\yolov5\\detect.py\", line 166, in run\n",
      "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\keo\\keo\\ntoday\\salesUP\\yolov5\\models\\common.py\", line 489, in __init__\n",
      "    model = attempt_load(str(weights) if isinstance(weights, list) else str(w), device=device, inplace=True, fuse=fuse)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\keo\\keo\\ntoday\\salesUP\\yolov5\\models\\experimental.py\", line 109, in attempt_load\n",
      "    ckpt = torch.load(str(ckpt_path), map_location=\"cpu\")  # load\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ntoday-mK10C09h-py3.12\\Lib\\site-packages\\ultralytics\\utils\\patches.py\", line 86, in torch_load\n",
      "    return _torch_load(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ntoday-mK10C09h-py3.12\\Lib\\site-packages\\torch\\serialization.py\", line 1425, in load\n",
      "    with _open_file_like(f, \"rb\") as opened_file:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ntoday-mK10C09h-py3.12\\Lib\\site-packages\\torch\\serialization.py\", line 751, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ntoday-mK10C09h-py3.12\\Lib\\site-packages\\torch\\serialization.py\", line 732, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "                     ^^^^^^^^^^^^^^^^\n",
      "OSError: [Errno 22] Invalid argument: '[C:\\\\keo\\\\keo\\\\ntoday\\\\salesUP\\\\yolov5\\\\runs\\\\train\\\\keoyolov5sresults\\\\weights\\\\best.pt]'\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/detect.py --weights \"C:\\\\keo\\\\keo\\\\ntoday\\\\salesUP\\\\yolov5\\\\runs\\\\train\\\\keoyolov5sresults\\\\weights\\\\best.pt\" --conf 0.5 --source \"image/KakaoTalk_20250210_145938006_01.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\keo\\\\keo\\\\ntoday\\\\salesUP'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 가중치 파일이 존재합니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "weights_path = (\n",
    "    \"C:/keo/keo/ntoday/salesUP/yolov5/runs/train/keo_yolov5s_results/weights/best.pt\"\n",
    ")\n",
    "\n",
    "if os.path.exists(weights_path):\n",
    "    print(\"✅ 가중치 파일이 존재합니다.\")\n",
    "else:\n",
    "    print(\"❌ 가중치 파일이 존재하지 않습니다. 다시 다운로드하세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_path = (\n",
    "    r\"C:/keo/keo/ntoday/salesUP/yolov5/runs/train/keo_yolov5s_results/weights/best.pt\"\n",
    ")\n",
    "\n",
    "command = (\n",
    "    f\"python yolov5/detect.py --weights {weights_path} --conf 0.5 --source images/\"\n",
    ")\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inference-cli\n",
      "  Downloading inference_cli-0.37.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from inference-cli) (2.32.3)\n",
      "Collecting docker<8.0.0,>=7.0.0 (from inference-cli)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting typer<=0.12.5,>=0.9.0 (from inference-cli)\n",
      "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: rich<13.10.0,>=13.0.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from inference-cli) (13.9.4)\n",
      "Requirement already satisfied: PyYAML~=6.0.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from inference-cli) (6.0.2)\n",
      "Requirement already satisfied: supervision<=0.30.0,>=0.25.1 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from inference-cli) (0.25.1)\n",
      "Requirement already satisfied: opencv-python<=4.10.0.84,>=4.8.1.78 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from inference-cli) (4.10.0.84)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from inference-cli) (4.67.1)\n",
      "Collecting nvidia-ml-py<13.0.0 (from inference-cli)\n",
      "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: py-cpuinfo~=9.0.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from inference-cli) (9.0.0)\n",
      "Requirement already satisfied: aiohttp<=3.10.11,>=3.9.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from inference-cli) (3.10.11)\n",
      "Requirement already satisfied: backoff~=2.2.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from inference-cli) (2.2.1)\n",
      "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from inference-cli) (2.2.3)\n",
      "Collecting rich<13.10.0,>=13.0.0 (from inference-cli)\n",
      "  Downloading rich-13.0.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pybase64~=1.0.0 (from inference-cli)\n",
      "  Downloading pybase64-1.0.2.tar.gz (105 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: pydantic~=2.6 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from inference-cli) (2.10.4)\n",
      "Requirement already satisfied: dataclasses-json~=0.6.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from inference-cli) (0.6.7)\n",
      "Requirement already satisfied: pillow<11.0,>=9.0.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from inference-cli) (10.4.0)\n",
      "Requirement already satisfied: numpy<=1.26.4 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from inference-cli) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-cli) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-cli) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-cli) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-cli) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-cli) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-cli) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from dataclasses-json~=0.6.0->inference-cli) (3.25.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from dataclasses-json~=0.6.0->inference-cli) (0.9.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from docker<8.0.0,>=7.0.0->inference-cli) (308)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from docker<8.0.0,>=7.0.0->inference-cli) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->inference-cli) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->inference-cli) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->inference-cli) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from pydantic~=2.6->inference-cli) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from pydantic~=2.6->inference-cli) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from pydantic~=2.6->inference-cli) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from requests<3.0.0,>=2.32.0->inference-cli) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from requests<3.0.0,>=2.32.0->inference-cli) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from requests<3.0.0,>=2.32.0->inference-cli) (2024.12.14)\n",
      "Collecting commonmark<0.10.0,>=0.9.0 (from rich<13.10.0,>=13.0.0->inference-cli)\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from rich<13.10.0,>=13.0.0->inference-cli) (2.18.0)\n",
      "Requirement already satisfied: contourpy>=1.0.7 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from supervision<=0.30.0,>=0.25.1->inference-cli) (1.3.1)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from supervision<=0.30.0,>=0.25.1->inference-cli) (0.7.1)\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from supervision<=0.30.0,>=0.25.1->inference-cli) (3.10.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from supervision<=0.30.0,>=0.25.1->inference-cli) (1.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from tqdm<5.0.0,>=4.0.0->inference-cli) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from typer<=0.12.5,>=0.9.0->inference-cli) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from typer<=0.12.5,>=0.9.0->inference-cli) (1.5.4)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json~=0.6.0->inference-cli) (24.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference-cli) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference-cli) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference-cli) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference-cli) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=2.0.0->inference-cli) (1.17.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json~=0.6.0->inference-cli) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ntoday-mk10c09h-py3.12\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<=3.10.11,>=3.9.0->inference-cli) (0.2.1)\n",
      "Downloading inference_cli-0.37.1-py3-none-any.whl (103 kB)\n",
      "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
      "Downloading rich-13.0.1-py3-none-any.whl (238 kB)\n",
      "Downloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "Building wheels for collected packages: pybase64\n",
      "  Building wheel for pybase64 (pyproject.toml): started\n",
      "  Building wheel for pybase64 (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pybase64: filename=pybase64-1.0.2-cp312-cp312-win_amd64.whl size=15473 sha256=4e4cf94b877eb538cd1f3d1139236018fb50058449c9616a58c74c6b29b56e24\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\ba\\62\\aa\\895a2495c012f960e827ad0930f338c7aea4708b677c44124a\n",
      "Successfully built pybase64\n",
      "Installing collected packages: nvidia-ml-py, commonmark, rich, pybase64, typer, docker, inference-cli\n",
      "  Attempting uninstall: rich\n",
      "    Found existing installation: rich 13.9.4\n",
      "    Uninstalling rich-13.9.4:\n",
      "      Successfully uninstalled rich-13.9.4\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.15.1\n",
      "    Uninstalling typer-0.15.1:\n",
      "      Successfully uninstalled typer-0.15.1\n",
      "Successfully installed commonmark-0.9.1 docker-7.1.0 inference-cli-0.37.1 nvidia-ml-py-12.570.86 pybase64-1.0.2 rich-13.0.1 typer-0.12.5\n",
      "Error connecting to Docker daemon. Is docker installed and running? See https://www.docker.com/get-started/ for installation instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "together 1.3.10 requires rich<14.0.0,>=13.8.1, but you have rich 13.0.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install inference-cli && inference server start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SyntaxWarning: invalid escape sequence '\\K'\n",
      "SyntaxWarning: invalid escape sequence '\\K'\n",
      "SyntaxWarning: invalid escape sequence '\\K'\n"
     ]
    }
   ],
   "source": [
    "from inference_sdk import InferenceHTTPClient\n",
    "\n",
    "client = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",  # use local inference server\n",
    "    api_key=\"Da0SeD9LCEl6rsnMvurC\",\n",
    ")\n",
    "\n",
    "result = client.run_workflow(\n",
    "    workspace_name=\"n2solution\",\n",
    "    workflow_id=\"custom-workflow-3\",\n",
    "    images={\"image\": \"image\\KakaoTalk_20250210_145938006_01.jpg\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\keo\\\\keo\\\\ntoday\\\\salesUP'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API 결과가 output/result.json 에 저장되었습니다.\n",
      "=== DEBUG: Raw 'result' Data ===\n",
      "[\n",
      "    {\n",
      "        \"predictions\": {\n",
      "            \"image\": {\n",
      "                \"width\": 1050,\n",
      "                \"height\": 1400\n",
      "            },\n",
      "            \"predictions\": [\n",
      "                {\n",
      "                    \"width\": 237.0,\n",
      "                    \"height\": 301.0,\n",
      "                    \"x\": 581.5,\n",
      "                    \"y\": 527.5,\n",
      "                    \"confidence\": 0.9383557438850403,\n",
      "                    \"class_id\": 0,\n",
      "                    \"class\": \"Electronic Shelf Label\",\n",
      "                    \"detection_id\": \"eb959e24-af0b-405f-990b-e3f50152689b\",\n",
      "                    \"parent_id\": \"image\"\n",
      "                },\n",
      "                {\n",
      "                    \"width\": 270.0,\n",
      "                    \"height\": 283.0,\n",
      "                    \"x\": 913.0,\n",
      "                    \"y\": 596.5,\n",
      "                    \"confidence\": 0.9166220426559448,\n",
      "                    \"class_id\": 0,\n",
      "                    \"class\": \"Electronic Shelf Label\",\n",
      "                    \"detection_id\": \"052270ce-c0f0-4669-a5ea-437e9001ee90\",\n",
      "                    \"parent_id\": \"image\"\n",
      "                },\n",
      "                {\n",
      "                    \"width\": 246.0,\n",
      "                    \"height\": 250.0,\n",
      "                    \"x\": 141.0,\n",
      "                    \"y\": 576.0,\n",
      "                    \"confidence\": 0.9134202599525452,\n",
      "                    \"class_id\": 0,\n",
      "                    \"class\": \"Electronic Shelf Label\",\n",
      "                    \"detection_id\": \"d326b551-9243-40e4-90f2-a53c161b0cb0\",\n",
      "                    \"parent_id\": \"image\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "] \n",
      "\n",
      "✅ 감지 결과 이미지가 output/detected_image.jpg 에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "\n",
    "# Roboflow API 클라이언트 설정\n",
    "client = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\", api_key=\"Da0SeD9LCEl6rsnMvurC\"\n",
    ")\n",
    "\n",
    "# 입력 이미지 및 출력 파일 경로\n",
    "image_path = \"image/1(1).jpg\"\n",
    "output_image_path = \"output/detected_image.jpg\"\n",
    "output_json_path = \"output/result.json\"\n",
    "\n",
    "try:\n",
    "    # API 요청 실행\n",
    "    result = client.run_workflow(\n",
    "        workspace_name=\"n2solution\",\n",
    "        workflow_id=\"custom-workflow-5\",\n",
    "        images={\"image\": image_path},\n",
    "    )\n",
    "\n",
    "    # 1) 결과 JSON 파일로 저장\n",
    "    with open(output_json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(result, json_file, indent=4, ensure_ascii=False)\n",
    "    print(f\"✅ API 결과가 {output_json_path} 에 저장되었습니다.\")\n",
    "\n",
    "    # 2) 디버그용 전체 result 구조 출력\n",
    "    print(\"=== DEBUG: Raw 'result' Data ===\")\n",
    "    print(json.dumps(result, ensure_ascii=False, indent=4), \"\\n\")\n",
    "\n",
    "    # 3) 원본 이미지 로드\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"⚠ 이미지 로드 실패: 파일 경로나 이미지 존재 여부를 확인하세요.\")\n",
    "        raise ValueError(\"이미지를 로드하지 못했습니다.\")\n",
    "\n",
    "    # 4) 'predictions' 파싱\n",
    "    # 제시된 JSON 구조:\n",
    "    # [\n",
    "    #   {\n",
    "    #     \"output\": {\n",
    "    #       \"image\": { \"width\": 1050, \"height\": 1400 },\n",
    "    #       \"predictions\": [\n",
    "    #         { \"width\":..., \"height\":..., \"x\":..., \"y\":..., \"confidence\":..., \"class\":... },\n",
    "    #         ...\n",
    "    #       ]\n",
    "    #     }\n",
    "    #   }\n",
    "    # ]\n",
    "\n",
    "    predictions = []\n",
    "    image_info = {}\n",
    "\n",
    "    # result는 list, 0번 인덱스는 dict, 그 안에 \"output\" 키가 존재하는지 확인\n",
    "    if (\n",
    "        isinstance(result, list)\n",
    "        and len(result) > 0\n",
    "        and isinstance(result[0], dict)\n",
    "        and \"predictions\" in result[0]\n",
    "    ):\n",
    "\n",
    "        output_data = result[0][\"predictions\"]\n",
    "\n",
    "        # output_data에 \"image\"와 \"predictions\" 키가 있는지 확인\n",
    "        if isinstance(output_data, dict):\n",
    "            image_info = output_data.get(\"image\", {})\n",
    "            predictions = output_data.get(\"predictions\", [])\n",
    "        else:\n",
    "            print(\"⚠ 'output'의 구조가 딕셔너리가 아닙니다.\")\n",
    "    else:\n",
    "        print(\"⚠ 결과 구조가 예상과 다릅니다. 디버그 출력을 확인하십시오.\")\n",
    "\n",
    "    # 5) 감지된 객체 처리\n",
    "    if not predictions:\n",
    "        print(\"⚠ 감지된 객체가 없습니다.\")\n",
    "    else:\n",
    "        # 이미지 크기 정보(필요시 사용)\n",
    "        image_width = image_info.get(\"width\", 0)\n",
    "        image_height = image_info.get(\"height\", 0)\n",
    "\n",
    "        # 바운딩 박스 시각화\n",
    "        for pred in predictions:\n",
    "            x = pred[\"x\"]\n",
    "            y = pred[\"y\"]\n",
    "            w = pred[\"width\"]\n",
    "            h = pred[\"height\"]\n",
    "            class_name = pred[\"class\"]\n",
    "            confidence = pred[\"confidence\"]\n",
    "\n",
    "            # 사각형 좌표\n",
    "            start_point = (int(x - w / 2), int(y - h / 2))\n",
    "            end_point = (int(x + w / 2), int(y + h / 2))\n",
    "\n",
    "            # 바운딩 박스 그리기\n",
    "            cv2.rectangle(image, start_point, end_point, (0, 255, 0), 2)\n",
    "\n",
    "            # 라벨 추가\n",
    "            label = f\"{class_name} ({confidence:.2f})\"\n",
    "            cv2.putText(\n",
    "                image,\n",
    "                label,\n",
    "                (start_point[0], start_point[1] - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 255, 0),\n",
    "                2,\n",
    "            )\n",
    "\n",
    "        # 6) 감지 결과 이미지 저장\n",
    "        cv2.imwrite(output_image_path, image)\n",
    "        print(f\"✅ 감지 결과 이미지가 {output_image_path} 에 저장되었습니다.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '285bb469-b85d-48ae-874c-974811bc2073', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 1346.0, 'height': 536.0, 'x': 1439.0, 'y': 2729.0, 'confidence': 0.4215283989906311, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '6649e9d2-80b4-4c07-90cd-a0fc8027d80b', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 1346.0, 'height': 536.0, 'x': 1439.0, 'y': 2729.0, 'confidence': 0.4215283989906311, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '6649e9d2-80b4-4c07-90cd-a0fc8027d80b', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_0.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_01.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '60c24def-8198-4039-8d67-b6102ed5886a', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 1183.0, 'height': 612.0, 'x': 1459.5, 'y': 2689.0, 'confidence': 0.8836033344268799, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'ebc32bf8-c4ce-4d93-8b91-c790fe2adbad', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_01.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 1183.0, 'height': 612.0, 'x': 1459.5, 'y': 2689.0, 'confidence': 0.8836033344268799, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'ebc32bf8-c4ce-4d93-8b91-c790fe2adbad', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_01_0.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006_01.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_02.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '6065c79d-099d-4fdd-b286-1b1b26a6bfd1', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 1163.0, 'height': 602.0, 'x': 2223.5, 'y': 2690.0, 'confidence': 0.895941436290741, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '93bd55e2-afa8-4af4-b4eb-a961baaf0727', 'parent_id': 'image'}, {'width': 1137.0, 'height': 623.0, 'x': 1090.5, 'y': 2672.5, 'confidence': 0.8846055865287781, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '35e89262-12bd-4108-969b-082e12196526', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_02.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 1163.0, 'height': 602.0, 'x': 2223.5, 'y': 2690.0, 'confidence': 0.895941436290741, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '93bd55e2-afa8-4af4-b4eb-a961baaf0727', 'parent_id': 'image'}, {'width': 1137.0, 'height': 623.0, 'x': 1090.5, 'y': 2672.5, 'confidence': 0.8846055865287781, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '35e89262-12bd-4108-969b-082e12196526', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_02_0.jpg\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_02_1.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006_02.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_03.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '1b85aede-78d1-4186-922b-a9fcb5d4aa28', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 1015.0, 'height': 464.0, 'x': 1941.5, 'y': 2458.0, 'confidence': 0.8988641500473022, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'aec57861-7ce3-4edd-8874-004fb57729e6', 'parent_id': 'image'}, {'width': 1081.0, 'height': 448.0, 'x': 851.5, 'y': 2470.0, 'confidence': 0.8864796161651611, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '83e2e1c5-178a-4706-b6b6-274ff1b1472e', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_03.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 1015.0, 'height': 464.0, 'x': 1941.5, 'y': 2458.0, 'confidence': 0.8988641500473022, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'aec57861-7ce3-4edd-8874-004fb57729e6', 'parent_id': 'image'}, {'width': 1081.0, 'height': 448.0, 'x': 851.5, 'y': 2470.0, 'confidence': 0.8864796161651611, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '83e2e1c5-178a-4706-b6b6-274ff1b1472e', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_03_0.jpg\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_03_1.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006_03.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_04.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': 'f5775402-81a6-4a4d-8b33-d361ac1d1446', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_04.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_05.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '339c0afd-8ce2-4fa8-bb32-d5ff243770e9', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_05.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_06.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': 'ed084321-0b81-4157-80b4-ea0cd826131a', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 862.0, 'height': 428.0, 'x': 1373.0, 'y': 2586.0, 'confidence': 0.9046496748924255, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '4bf00fb0-51b5-4a82-966a-f2f031367843', 'parent_id': 'image'}, {'width': 1063.0, 'height': 212.0, 'x': 1495.5, 'y': 2892.0, 'confidence': 0.7246197462081909, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'c1807654-f644-4f5f-aa66-94dd7f068f11', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_06.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 862.0, 'height': 428.0, 'x': 1373.0, 'y': 2586.0, 'confidence': 0.9046496748924255, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '4bf00fb0-51b5-4a82-966a-f2f031367843', 'parent_id': 'image'}, {'width': 1063.0, 'height': 212.0, 'x': 1495.5, 'y': 2892.0, 'confidence': 0.7246197462081909, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'c1807654-f644-4f5f-aa66-94dd7f068f11', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_06_0.jpg\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_06_1.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006_06.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_07.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '81abafa2-7211-4f6a-bcae-91b3e3896dc8', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_07.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_08.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '58047e02-0737-414d-8826-181cda3ccc06', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 1411.0, 'height': 718.0, 'x': 1408.5, 'y': 2318.0, 'confidence': 0.9140022397041321, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '831cc6be-6382-4e41-a08d-d83fb11b5da2', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_08.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 1411.0, 'height': 718.0, 'x': 1408.5, 'y': 2318.0, 'confidence': 0.9140022397041321, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '831cc6be-6382-4e41-a08d-d83fb11b5da2', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_08_0.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006_08.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_09.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': 'dc110f0b-e3e5-46c8-9cdb-ea1df467f344', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 1336.0, 'height': 648.0, 'x': 1320.0, 'y': 2346.0, 'confidence': 0.9017285108566284, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'b01ecb1f-df81-49b7-b89f-9475026ddbad', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_09.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 1336.0, 'height': 648.0, 'x': 1320.0, 'y': 2346.0, 'confidence': 0.9017285108566284, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'b01ecb1f-df81-49b7-b89f-9475026ddbad', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_09_0.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006_09.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_10.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '5db8ffbb-6d69-405d-a23d-900d148b4cf5', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 1562.0, 'height': 730.0, 'x': 2287.0, 'y': 2013.0, 'confidence': 0.9425543546676636, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '1e4274f0-52e7-44ad-94e1-5f0c7f2f57dd', 'parent_id': 'image'}, {'width': 1481.0, 'height': 723.0, 'x': 740.5, 'y': 2010.5, 'confidence': 0.9346598982810974, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'ca9dfc22-0397-4f9d-90d8-433201d2b614', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_10.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 1562.0, 'height': 730.0, 'x': 2287.0, 'y': 2013.0, 'confidence': 0.9425543546676636, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '1e4274f0-52e7-44ad-94e1-5f0c7f2f57dd', 'parent_id': 'image'}, {'width': 1481.0, 'height': 723.0, 'x': 740.5, 'y': 2010.5, 'confidence': 0.9346598982810974, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'ca9dfc22-0397-4f9d-90d8-433201d2b614', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_10_0.jpg\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_10_1.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006_10.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_11.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '46a7829f-64b2-4cdc-81c4-aa05823210bb', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 1793.0, 'height': 876.0, 'x': 2516.5, 'y': 1781.0, 'confidence': 0.9304579496383667, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'd9d8aaf0-a1a1-4d54-b669-1165ebacedda', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_11.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 1793.0, 'height': 876.0, 'x': 2516.5, 'y': 1781.0, 'confidence': 0.9304579496383667, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'd9d8aaf0-a1a1-4d54-b669-1165ebacedda', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_11_0.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006_11.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_12.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '2e82c85a-7a13-4db8-82b5-bb90b07363eb', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 1785.0, 'height': 849.0, 'x': 2967.5, 'y': 1280.5, 'confidence': 0.9313204884529114, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'ec7f2b23-98b3-43bb-aabd-75636842292e', 'parent_id': 'image'}, {'width': 1672.0, 'height': 831.0, 'x': 1228.0, 'y': 1279.5, 'confidence': 0.9247269630432129, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'b5d06323-f735-4aab-a8c9-f26ccce84d0a', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_12.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 1785.0, 'height': 849.0, 'x': 2967.5, 'y': 1280.5, 'confidence': 0.9313204884529114, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'ec7f2b23-98b3-43bb-aabd-75636842292e', 'parent_id': 'image'}, {'width': 1672.0, 'height': 831.0, 'x': 1228.0, 'y': 1279.5, 'confidence': 0.9247269630432129, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'b5d06323-f735-4aab-a8c9-f26ccce84d0a', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_12_0.jpg\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_12_1.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006_12.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_13.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': 'c14d27bd-9e4d-43af-a198-60e05629b2cc', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 1521.0, 'height': 807.0, 'x': 3230.5, 'y': 1733.5, 'confidence': 0.9316534996032715, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'b3e5449e-7211-4cd9-b7c3-73f86931e181', 'parent_id': 'image'}, {'width': 1683.0, 'height': 825.0, 'x': 1589.5, 'y': 1712.5, 'confidence': 0.9280428290367126, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '0f25e6ef-b710-4237-93a9-28e2b7085fe2', 'parent_id': 'image'}, {'width': 589.0, 'height': 861.0, 'x': 298.5, 'y': 1704.5, 'confidence': 0.8375554084777832, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '6e8df873-4a9e-448d-ac76-f6197c8ab9d8', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_13.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 1521.0, 'height': 807.0, 'x': 3230.5, 'y': 1733.5, 'confidence': 0.9316534996032715, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'b3e5449e-7211-4cd9-b7c3-73f86931e181', 'parent_id': 'image'}, {'width': 1683.0, 'height': 825.0, 'x': 1589.5, 'y': 1712.5, 'confidence': 0.9280428290367126, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '0f25e6ef-b710-4237-93a9-28e2b7085fe2', 'parent_id': 'image'}, {'width': 589.0, 'height': 861.0, 'x': 298.5, 'y': 1704.5, 'confidence': 0.8375554084777832, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '6e8df873-4a9e-448d-ac76-f6197c8ab9d8', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_13_0.jpg\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_13_1.jpg\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_13_2.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006_13.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_14.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '9de3c6b9-d014-47b5-b7d0-4d997149d80b', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 1462.0, 'height': 737.0, 'x': 1582.0, 'y': 1784.5, 'confidence': 0.9387450218200684, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '8400b3ed-de10-4df6-8dd1-c2af7ca9206d', 'parent_id': 'image'}, {'width': 1485.0, 'height': 732.0, 'x': 3150.5, 'y': 1782.0, 'confidence': 0.9363433122634888, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'ce3a53ca-57fa-4d20-9ae6-a27758a95869', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_14.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 1462.0, 'height': 737.0, 'x': 1582.0, 'y': 1784.5, 'confidence': 0.9387450218200684, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '8400b3ed-de10-4df6-8dd1-c2af7ca9206d', 'parent_id': 'image'}, {'width': 1485.0, 'height': 732.0, 'x': 3150.5, 'y': 1782.0, 'confidence': 0.9363433122634888, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'ce3a53ca-57fa-4d20-9ae6-a27758a95869', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_14_0.jpg\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_14_1.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006_14.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_15.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': 'f619ef40-061d-4deb-acc9-ae9b6a9d6311', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 1280.0, 'height': 638.0, 'x': 1245.0, 'y': 1665.0, 'confidence': 0.9357842803001404, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'e543f2f2-3d13-43ce-9a45-980c8dd32a24', 'parent_id': 'image'}, {'width': 1430.0, 'height': 652.0, 'x': 3021.0, 'y': 1660.0, 'confidence': 0.9313023090362549, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '1e4096b3-618d-480b-a3eb-e7bd11f0b730', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_15.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 1280.0, 'height': 638.0, 'x': 1245.0, 'y': 1665.0, 'confidence': 0.9357842803001404, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'e543f2f2-3d13-43ce-9a45-980c8dd32a24', 'parent_id': 'image'}, {'width': 1430.0, 'height': 652.0, 'x': 3021.0, 'y': 1660.0, 'confidence': 0.9313023090362549, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '1e4096b3-618d-480b-a3eb-e7bd11f0b730', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_15_0.jpg\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_15_1.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006_15.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_16.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '2c969329-4323-4553-8577-9fcf1ad001c8', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 1139.0, 'height': 574.0, 'x': 1071.5, 'y': 1659.0, 'confidence': 0.9356142282485962, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '8f5cc7b5-a9e2-43b6-9906-8fb9b0c76d88', 'parent_id': 'image'}, {'width': 1293.0, 'height': 596.0, 'x': 3026.5, 'y': 1640.0, 'confidence': 0.928007960319519, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '46a9f9ce-94ed-41c2-b79a-428acd4816a5', 'parent_id': 'image'}, {'width': 143.0, 'height': 581.0, 'x': 75.5, 'y': 1695.5, 'confidence': 0.4391334652900696, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'bd39c960-c13b-4bed-9c9e-5404e823489e', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_16.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 1139.0, 'height': 574.0, 'x': 1071.5, 'y': 1659.0, 'confidence': 0.9356142282485962, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '8f5cc7b5-a9e2-43b6-9906-8fb9b0c76d88', 'parent_id': 'image'}, {'width': 1293.0, 'height': 596.0, 'x': 3026.5, 'y': 1640.0, 'confidence': 0.928007960319519, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '46a9f9ce-94ed-41c2-b79a-428acd4816a5', 'parent_id': 'image'}, {'width': 143.0, 'height': 581.0, 'x': 75.5, 'y': 1695.5, 'confidence': 0.4391334652900696, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'bd39c960-c13b-4bed-9c9e-5404e823489e', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_16_0.jpg\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_16_1.jpg\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_16_2.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006_16.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_17.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '819b37ec-16ce-4f37-bb5b-da8002854017', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 1841.0, 'height': 854.0, 'x': 1948.5, 'y': 2055.0, 'confidence': 0.935784101486206, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '3588bb24-893b-4232-9178-09908212e4bb', 'parent_id': 'image'}, {'width': 1105.0, 'height': 893.0, 'x': 3443.5, 'y': 2111.5, 'confidence': 0.9093798398971558, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '92f0fe75-7cb3-4b9c-a972-73ec40ac881c', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_17.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 1841.0, 'height': 854.0, 'x': 1948.5, 'y': 2055.0, 'confidence': 0.935784101486206, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '3588bb24-893b-4232-9178-09908212e4bb', 'parent_id': 'image'}, {'width': 1105.0, 'height': 893.0, 'x': 3443.5, 'y': 2111.5, 'confidence': 0.9093798398971558, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '92f0fe75-7cb3-4b9c-a972-73ec40ac881c', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_17_0.jpg\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_17_1.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006_17.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_18.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': 'b6fe159b-1205-4c8f-bf63-372340a0c46e', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 866.0, 'height': 698.0, 'x': 433.0, 'y': 1826.0, 'confidence': 0.9312078356742859, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'e5f63a3d-352b-406a-adc6-aeb898fba452', 'parent_id': 'image'}, {'width': 1455.0, 'height': 710.0, 'x': 1596.5, 'y': 1838.0, 'confidence': 0.926855206489563, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '897128bb-d20e-42a3-9d93-af2a00335e31', 'parent_id': 'image'}, {'width': 1629.0, 'height': 744.0, 'x': 3160.5, 'y': 1856.0, 'confidence': 0.9259608387947083, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'bd8a728c-074a-496c-857c-3068384edae7', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_18.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 866.0, 'height': 698.0, 'x': 433.0, 'y': 1826.0, 'confidence': 0.9312078356742859, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'e5f63a3d-352b-406a-adc6-aeb898fba452', 'parent_id': 'image'}, {'width': 1455.0, 'height': 710.0, 'x': 1596.5, 'y': 1838.0, 'confidence': 0.926855206489563, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '897128bb-d20e-42a3-9d93-af2a00335e31', 'parent_id': 'image'}, {'width': 1629.0, 'height': 744.0, 'x': 3160.5, 'y': 1856.0, 'confidence': 0.9259608387947083, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'bd8a728c-074a-496c-857c-3068384edae7', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_18_0.jpg\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_18_1.jpg\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_18_2.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006_18.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_19.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '9ce49e08-e562-4ec9-9940-3c5c22baba6c', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 1491.0, 'height': 691.0, 'x': 1405.5, 'y': 1755.5, 'confidence': 0.9364730715751648, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '072eb181-f2aa-4340-8624-f98b8629392b', 'parent_id': 'image'}, {'width': 1475.0, 'height': 684.0, 'x': 3176.5, 'y': 1753.0, 'confidence': 0.927982747554779, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '39582eee-04f0-4cbd-b9c8-b0d3dc69b657', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_19.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 1491.0, 'height': 691.0, 'x': 1405.5, 'y': 1755.5, 'confidence': 0.9364730715751648, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '072eb181-f2aa-4340-8624-f98b8629392b', 'parent_id': 'image'}, {'width': 1475.0, 'height': 684.0, 'x': 3176.5, 'y': 1753.0, 'confidence': 0.927982747554779, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '39582eee-04f0-4cbd-b9c8-b0d3dc69b657', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_19_0.jpg\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_19_1.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006_19.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_145938006_20.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '7394aace-a760-4aaa-9dfd-e4b4dc0364fc', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 1829.0, 'height': 861.0, 'x': 1187.5, 'y': 1434.5, 'confidence': 0.929106593132019, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'a4166986-f034-473d-abe4-672310ccbd92', 'parent_id': 'image'}, {'width': 1760.0, 'height': 863.0, 'x': 3032.0, 'y': 1468.5, 'confidence': 0.9237605333328247, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'd3a06102-fefc-43de-9446-51ce9dc15799', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_145938006_20.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 1829.0, 'height': 861.0, 'x': 1187.5, 'y': 1434.5, 'confidence': 0.929106593132019, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'a4166986-f034-473d-abe4-672310ccbd92', 'parent_id': 'image'}, {'width': 1760.0, 'height': 863.0, 'x': 3032.0, 'y': 1468.5, 'confidence': 0.9237605333328247, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'd3a06102-fefc-43de-9446-51ce9dc15799', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_20_0.jpg\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_145938006_20_1.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_145938006_20.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_184141265.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '399a9d5a-49de-4544-9d05-40d4865c3af9', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_184141265.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_184141265_01.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': 'e788669c-ee1a-45f6-bf93-5fe35b3e06ec', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 2099.0, 'height': 250.0, 'x': 1440.5, 'y': 2873.0, 'confidence': 0.43923699855804443, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'f2ee6367-6fc7-49e6-a665-f6a3c6755fdc', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_184141265_01.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 2099.0, 'height': 250.0, 'x': 1440.5, 'y': 2873.0, 'confidence': 0.43923699855804443, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': 'f2ee6367-6fc7-49e6-a665-f6a3c6755fdc', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_184141265_01_0.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_184141265_01.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_184141265_02.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '8b5ea028-30b3-43cb-ae0c-6f0791a2e8a9', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_184141265_02.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_184141265_03.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '37795b72-714f-4436-8084-e8613fce47e4', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_184141265_03.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_184141265_04.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '728624fb-c2d8-4ebf-8019-f59829310a5c', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_184141265_04.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_184141265_05.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': 'ff6b6828-fc1d-45ae-86ed-6069cbdbf7b0', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_184141265_05.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_184141265_06.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': 'f7988131-43b3-4249-bc93-ea62e77e52c8', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_184141265_06.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_184141265_07.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '7ec05dc6-a1c6-4f1f-bf7a-a9d56c8725da', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_184141265_07.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_184141265_08.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '540965d6-2915-400a-84f3-f8bb5d2a8bde', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_184141265_08.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_184141265_09.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': 'f2d40525-27ce-4d62-bf87-654471c6f29a', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_184141265_09.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_184141265_10.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': 'c1f0bc9c-a224-401a-98ac-7c0aec33534f', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_184141265_10.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_184141265_11.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': 'bac1e647-79df-43f9-b084-a4b35e4828cf', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_184141265_11.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_184141265_12.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '1574e4ae-5fcf-4720-88b2-2d7269248173', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_184141265_12.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_184141265_13.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '9eecebc2-81d7-4cb9-af57-77bdfbeadb56', 'predictions': {'image': {'width': 4000, 'height': 3000}, 'predictions': [{'width': 1388.0, 'height': 61.0, 'x': 832.0, 'y': 2968.5, 'confidence': 0.4811035692691803, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '4cc5220e-fe3b-4981-a380-8ffce5f9a2c8', 'parent_id': 'image'}]}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_184141265_13.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: [{'width': 1388.0, 'height': 61.0, 'x': 832.0, 'y': 2968.5, 'confidence': 0.4811035692691803, 'class_id': 0, 'class': 'Electronic Shelf Label', 'detection_id': '4cc5220e-fe3b-4981-a380-8ffce5f9a2c8', 'parent_id': 'image'}]\n",
      "  ✅ Cropped 이미지 저장: output/crops\\KakaoTalk_20250210_184141265_13_0.jpg\n",
      "  ✅ Annotated 이미지 저장: output/detected\\KakaoTalk_20250210_184141265_13.jpg\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_184141265_14.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '0cceeab4-43ba-45a0-b24b-b73ef0b9e94e', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_184141265_14.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_184141265_15.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': 'ba8c6d92-aa75-4ea2-8d05-f1dc5052d636', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_184141265_15.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n",
      "\n",
      "[INFO] 처리 중: KakaoTalk_20250210_184141265_16.jpg\n",
      "[DEBUG] result 타입: <class 'list'>\n",
      "[DEBUG] result 내용: [{'predictions': {'inference_id': '895b03d5-aafc-499f-b0e4-03f716756d59', 'predictions': {'image': {'width': None, 'height': None}, 'predictions': []}}}]\n",
      "  ✅ JSON 결과 저장: output/json\\KakaoTalk_20250210_184141265_16.json\n",
      "[DEBUG] predictions 타입: <class 'list'>\n",
      "[DEBUG] predictions 내용: []\n",
      "  ⚠ 감지된 객체가 없습니다.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "\n",
    "# 입력 폴더 및 출력 폴더 설정\n",
    "input_folder = \"image\"  # 처리할 이미지가 있는 폴더\n",
    "output_folder_detected = \"output/detected\"  # 바운딩 박스가 그려진 이미지 저장 폴더\n",
    "output_folder_json = \"output/json\"  # JSON 결과 저장 폴더\n",
    "output_folder_crops = \"output/crops\"  # 크롭된 객체 이미지 저장 폴더\n",
    "\n",
    "# 출력 폴더가 없으면 생성\n",
    "os.makedirs(output_folder_detected, exist_ok=True)\n",
    "os.makedirs(output_folder_json, exist_ok=True)\n",
    "os.makedirs(output_folder_crops, exist_ok=True)\n",
    "\n",
    "# Roboflow API 클라이언트 설정\n",
    "client = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\", api_key=\"Da0SeD9LCEl6rsnMvurC\"\n",
    ")\n",
    "\n",
    "# 지원할 이미지 확장자 목록\n",
    "image_extensions = [\"*.jpg\", \"*.jpeg\", \"*.png\"]\n",
    "image_paths = []\n",
    "for ext in image_extensions:\n",
    "    image_paths.extend(glob.glob(os.path.join(input_folder, ext)))\n",
    "\n",
    "# 각 이미지 처리\n",
    "for image_path in image_paths:\n",
    "    base_filename = os.path.basename(image_path)\n",
    "    print(f\"\\n[INFO] 처리 중: {base_filename}\")\n",
    "\n",
    "    try:\n",
    "        # API 요청 실행\n",
    "        result = client.run_workflow(\n",
    "            workspace_name=\"n2solution\",\n",
    "            workflow_id=\"custom-workflow-5\",\n",
    "            images={\"image\": image_path},\n",
    "        )\n",
    "\n",
    "        # 디버깅: 결과의 타입과 내용 확인\n",
    "        print(\"[DEBUG] result 타입:\", type(result))\n",
    "        print(\"[DEBUG] result 내용:\", result)\n",
    "\n",
    "        # JSON 결과 저장 (파일명: 원본파일명.json)\n",
    "        json_filename = os.path.splitext(base_filename)[0] + \".json\"\n",
    "        json_path = os.path.join(output_folder_json, json_filename)\n",
    "        with open(json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "            json.dump(result, json_file, indent=4, ensure_ascii=False)\n",
    "        print(f\"  ✅ JSON 결과 저장: {json_path}\")\n",
    "\n",
    "        # 원본 이미지 로드\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(\"  ⚠ 이미지 로드 실패\")\n",
    "            continue\n",
    "\n",
    "        # 결과 JSON 파싱\n",
    "        predictions = []\n",
    "        image_info = {}\n",
    "        if (\n",
    "            isinstance(result, list)\n",
    "            and len(result) > 0\n",
    "            and isinstance(result[0], dict)\n",
    "            and \"predictions\" in result[0]\n",
    "        ):\n",
    "            outer_data = result[0][\"predictions\"]\n",
    "            # outer_data는 \"inference_id\"와 \"predictions\" 키를 가짐\n",
    "            inner_data = outer_data.get(\"predictions\", {})\n",
    "            if isinstance(inner_data, dict):\n",
    "                image_info = inner_data.get(\"image\", {})\n",
    "                predictions = inner_data.get(\"predictions\", [])\n",
    "            elif isinstance(inner_data, list):\n",
    "                predictions = inner_data\n",
    "            else:\n",
    "                print(\"  ⚠ inner 'predictions'의 구조가 예상과 다릅니다.\")\n",
    "                continue\n",
    "        else:\n",
    "            print(\"  ⚠ 결과 구조가 예상과 다릅니다.\")\n",
    "            continue\n",
    "\n",
    "        # 디버깅: predictions의 타입과 내용 확인\n",
    "        print(\"[DEBUG] predictions 타입:\", type(predictions))\n",
    "        print(\"[DEBUG] predictions 내용:\", predictions)\n",
    "\n",
    "        # 원본 이미지 복사 (바운딩 박스 그리기 용)\n",
    "        annotated_image = image.copy()\n",
    "\n",
    "        # 예측 결과 처리\n",
    "        if not predictions:\n",
    "            print(\"  ⚠ 감지된 객체가 없습니다.\")\n",
    "        else:\n",
    "            for idx, pred in enumerate(predictions):\n",
    "                # 만약 개별 예측 항목이 문자열이면 JSON 파싱 시도 (보통은 이미 dict여야 함)\n",
    "                if isinstance(pred, str):\n",
    "                    try:\n",
    "                        pred = json.loads(pred)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"[DEBUG] 예측 결과 파싱 실패 idx {idx}: {e}\")\n",
    "                        continue\n",
    "                if not isinstance(pred, dict):\n",
    "                    print(f\"[DEBUG] 예측 결과 idx {idx}가 딕셔너리가 아님: {pred}\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    x = pred[\"x\"]\n",
    "                    y = pred[\"y\"]\n",
    "                    w = pred[\"width\"]\n",
    "                    h = pred[\"height\"]\n",
    "                    class_name = pred[\"class\"]\n",
    "                    confidence = pred[\"confidence\"]\n",
    "                except Exception as e:\n",
    "                    print(f\"[DEBUG] 예측 결과 idx {idx} 처리 중 오류: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # 좌표 계산 (중심 좌표와 크기를 바탕으로)\n",
    "                left = int(x - w / 2)\n",
    "                top = int(y - h / 2)\n",
    "                right = int(x + w / 2)\n",
    "                bottom = int(y + h / 2)\n",
    "\n",
    "                # 이미지 경계를 벗어나지 않도록 조정\n",
    "                left = max(left, 0)\n",
    "                top = max(top, 0)\n",
    "                right = min(right, image.shape[1])\n",
    "                bottom = min(bottom, image.shape[0])\n",
    "\n",
    "                # 바운딩 박스 그리기\n",
    "                cv2.rectangle(\n",
    "                    annotated_image, (left, top), (right, bottom), (0, 255, 0), 2\n",
    "                )\n",
    "                label = f\"{class_name} ({confidence:.2f})\"\n",
    "                cv2.putText(\n",
    "                    annotated_image,\n",
    "                    label,\n",
    "                    (left, top - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (0, 255, 0),\n",
    "                    2,\n",
    "                )\n",
    "\n",
    "                # 바운딩 박스 영역 크롭 및 저장 (파일명: 원본파일명_인덱스.jpg)\n",
    "                crop = image[top:bottom, left:right]\n",
    "                crop_filename = os.path.splitext(base_filename)[0] + f\"_{idx}.jpg\"\n",
    "                crop_path = os.path.join(output_folder_crops, crop_filename)\n",
    "                cv2.imwrite(crop_path, crop)\n",
    "                print(f\"  ✅ Cropped 이미지 저장: {crop_path}\")\n",
    "\n",
    "            # 바운딩 박스가 그려진 이미지 저장 (원본 파일명 사용)\n",
    "            detected_image_path = os.path.join(output_folder_detected, base_filename)\n",
    "            cv2.imwrite(detected_image_path, annotated_image)\n",
    "            print(f\"  ✅ Annotated 이미지 저장: {detected_image_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 파일 처리 중: KakaoTalk_20250226_111541090.jpg\n",
      "[INFO] 파일 처리 중: KakaoTalk_20250226_111541090_01.jpg\n",
      "[INFO] 파일 처리 중: KakaoTalk_20250226_111541090_02.jpg\n",
      "[INFO] 파일 처리 중: KakaoTalk_20250226_111541090_03.jpg\n",
      "[INFO] 파일 처리 중: KakaoTalk_20250226_111541090_04.jpg\n",
      "[INFO] 파일 처리 중: KakaoTalk_20250226_111541090_05.jpg\n",
      "[INFO] 파일 처리 중: KakaoTalk_20250226_111541090_06.jpg\n",
      "[INFO] 파일 처리 중: KakaoTalk_20250226_111541090_07.jpg\n",
      "✅ 모든 파일의 CSV 데이터가 output/combined.csv 에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "from langchain_teddynote.prompts import load_prompt\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "api_key = \"up_Mw8PEw6k3ehZqrZbQ9WfUcCPIysnn\"\n",
    "url = \"https://api.upstage.ai/v1/document-ai/ocr\"\n",
    "headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "\n",
    "# OCR 처리할 이미지가 있는 폴더\n",
    "image_folder = \"output/crops\"\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith((\".jpg\", \".png\"))]\n",
    "\n",
    "# LangChain 프롬프트 로드\n",
    "prompt = load_prompt(\"prompt/crops.yaml\", encoding=\"utf-8\")\n",
    "\n",
    "# 언어 모델 및 체인 생성\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 모든 파일의 CSV 데이터를 합칠 리스트\n",
    "combined_rows = []\n",
    "header_added = False  # 헤더 행 추가 여부 체크\n",
    "\n",
    "for filename in image_files:\n",
    "    image_path = os.path.join(image_folder, filename)\n",
    "    print(f\"[INFO] 파일 처리 중: {filename}\")\n",
    "\n",
    "    # 이미지 파일을 OCR API로 전송\n",
    "    with open(image_path, \"rb\") as file:\n",
    "        files = {\"document\": file}\n",
    "        response = requests.post(url, headers=headers, files=files)\n",
    "        response_data = response.json()\n",
    "\n",
    "    # OCR 결과에서 \"pages\" 배열 내 각 페이지의 text만 추출\n",
    "    pages = response_data.get(\"pages\", [])\n",
    "    if not pages:\n",
    "        print(f\"  ⚠ OCR 결과에 'pages' 데이터가 없습니다. 파일: {filename}\")\n",
    "        continue\n",
    "\n",
    "    texts = [page.get(\"text\", \"\") for page in pages]\n",
    "    full_text = \"\\n\".join(texts)\n",
    "    if not full_text:\n",
    "        print(f\"  ⚠ OCR 결과에서 텍스트를 추출하지 못했습니다. 파일: {filename}\")\n",
    "        continue\n",
    "\n",
    "    # OCR 텍스트 전처리 (필요시 쉼표 제거 등)\n",
    "    data = full_text.replace(\",\", \"\")\n",
    "\n",
    "    # LangChain 체인 호출: OCR 텍스트를 CSV 형식으로 변환\n",
    "    result = chain.invoke(\n",
    "        {\"context\": data, \"question\": \"context를 csv 형식으로 변환해줘\"}\n",
    "    )\n",
    "\n",
    "    # 결과를 줄 단위로 분리 후 불필요한 구문 제거\n",
    "    csv_data = result.split(\"\\n\")\n",
    "    filtered_data = []\n",
    "    record = False\n",
    "    for line in csv_data:\n",
    "        if '\"\"\"' in line or \"```\" in line:\n",
    "            continue\n",
    "        if \"상품명\" in line:\n",
    "            record = True\n",
    "        if record:\n",
    "            filtered_data.append(line)\n",
    "\n",
    "    if not filtered_data:\n",
    "        print(f\"  ⚠ {filename} 파일에 대해 CSV 데이터가 생성되지 않았습니다.\")\n",
    "        continue\n",
    "\n",
    "    # 각 줄을 리스트로 변환 (쉼표 기준 분리)\n",
    "    rows = [row.split(\",\") for row in filtered_data]\n",
    "\n",
    "    # 최초 파일인 경우 헤더 행(예: \"상품명\" 포함 행)을 추가하고, 이후 파일은 데이터 행만 추가\n",
    "    if not header_added:\n",
    "        header = rows[0]\n",
    "        header.append(\"source\")  # 출처(파일명) 컬럼 추가\n",
    "        combined_rows.append(header)\n",
    "        header_added = True\n",
    "        data_rows = rows[1:]\n",
    "    else:\n",
    "        data_rows = rows[1:]\n",
    "\n",
    "    # 각 데이터 행 끝에 파일명을 추가한 후 combined_rows에 합치기\n",
    "    for row in data_rows:\n",
    "        row.append(filename)\n",
    "        combined_rows.append(row)\n",
    "\n",
    "# 합쳐진 CSV 데이터를 하나의 파일로 저장 (예: output/combined.csv)\n",
    "combined_csv_path = \"output/combined.csv\"\n",
    "with open(combined_csv_path, mode=\"w\", newline=\"\", encoding=\"utf-8-sig\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(combined_rows)\n",
    "\n",
    "print(f\"✅ 모든 파일의 CSV 데이터가 {combined_csv_path} 에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntoday-mK10C09h-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
