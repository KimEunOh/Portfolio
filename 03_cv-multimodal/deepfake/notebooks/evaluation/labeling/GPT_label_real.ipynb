{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "Deepfakes\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"Deepfakes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"\"\"\n",
    "**1. Key Facial Features Analysis**  \n",
    "- **Alignment, proportions, and symmetry**: Look carefully at the alignment, proportions, and symmetry of key facial features such as the eyes, nose, mouth, and ears. Pay attention to any discrepancies, asymmetries, or unnatural positioning. Specifically, look for:\n",
    "   - **Gaze inconsistencies**: Gaze that does not align with the camera or eyes that appear to be looking in different directions.\n",
    "   - **Pupil reflection, asymmetry, and shape**: Odd or asymmetrical light reflections in the pupils, reflections that do not match natural eye reflection patterns, or pupils that appear unusually shaped or inconsistent with typical roundness. Look for any irregular pupil shapes that might indicate manipulation.\n",
    "- **Unnatural aspects**: Identify any facial features that look deformed or artificial, such as exaggerated or distorted shapes, unusual placements, and abnormal positioning relative to other facial elements.\n",
    "- **Awkward lip shape and ambiguous teeth presentation**: Look for unnatural contours of the lips when the mouth is closed and simplified or unclear presentation of teeth when the mouth is open.\n",
    "\n",
    "**2. Skin Texture and Tone Analysis**  \n",
    "- **Texture, smoothness, and tone transitions**: Examine the texture, smoothness, and tone transitions of the skin across the face. Look for:\n",
    "   - **Unnaturally smooth areas** or repetitive patterns that suggest manipulation, including strange pixelation, blurriness, or sections that appear overly smooth, as if digitally airbrushed.\n",
    "   - **Irregular tone transitions** between shadows and highlights, or overly uniform skin tones that lack the natural variation typical of human skin.\n",
    "- **Differences in skin colour between the face and neck**: Check for unnatural colour or lighting mismatches between the face and neck.\n",
    "\n",
    "**3. Low-Level Detail Inspection**  \n",
    "- **Edges and borders**: Examine the edges where the face meets the background or where facial features meet the rest of the face. Look for blended or jagged edges that could suggest digital manipulation. Watch for blurry or overly smooth boundaries that may not match natural anatomy.\n",
    "- **Sharpness and distortion**: Look for unnatural sharpness or distortion in specific areas, such as overly sharp or blurred eye sockets, suggesting artificial enhancement.\n",
    "- **Tone and contrast**: Assess the tone and contrast across the face or between facial features. Unnaturally high contrast or abrupt shading changes may indicate manipulation.\n",
    "- **Layout and symmetry**: Examine the face's overall layout and symmetry. Human faces generally follow natural symmetry principles. Look for asymmetries such as uneven eye size, tilted lips, or a misaligned jaw.\n",
    "- **Reflections and shadows**: Check for inconsistencies in reflections and shadows. For example, reflections in the eyes should match the direction of light and shadows on the face. Inconsistent shadows or light sources can indicate manipulation.\n",
    "- **Perspective and shape**: Ensure the perspective and shape of facial features are logically consistent with the head’s orientation. Discrepancies, like eyes appearing unnaturally close to the camera or an out-of-place nose, could indicate manipulation.\n",
    "- **Mismatch between face and body proportions**: The face may appear disproportionately large or small compared to the body, or proportions may not match.\n",
    "- **Blurry texture of hair at high resolution**: Hair around the face may appear blurry or crude at high resolution, especially if it is unusually smooth or well-groomed.\n",
    "\n",
    "**4. Lighting, Theme, and Environment Consistency**  \n",
    "- **Lighting and shadow consistency**: Assess whether the lighting and environment are coherent. Look specifically for:\n",
    "   - **Inconsistent shadows or lighting**: Shadows that do not align with the light source, or highlights and shadows that appear inconsistent with the light direction on the face.\n",
    "   - **Light reflection imbalance**: Unnatural reflections or inconsistent size and direction of light on the skin or eyes.\n",
    "- **Theme consistency**: Check if the overall scene coherence, mood, and context of the image are consistent with lighting and environment. Look for overly stylized backgrounds with hyper-realistic faces or facial expressions mismatched with the context.\n",
    "\n",
    "**5. Additional Deepfake Clues**  \n",
    "- **Subtle facial expressions and muscle movements**: Analyse the subtle muscle movements and micro-expressions on the face. Deepfakes often struggle with natural expressions, resulting in unnatural stiffness or a frozen appearance, especially around key areas like the jaw, eyes, and lips.\n",
    "- **Distortion of wrinkles around the eyes and nose**: Check for abnormal wrinkles around the eyes and nose or limited movement of facial muscles when smiling or frowning.\n",
    "\n",
    "---\n",
    "\n",
    "**The Bottom Line**  \n",
    "This guide covers key facial features, skin texture, low-level details, lighting and environment, and subtle facial expressions to detect deepfake clues. Be thorough and look for any inconsistencies, even in the smallest details, as each aspect may reveal manipulation.\n",
    "By focusing on the above aspects, your analysis should serve to document and reinforce why the images are undeniably real, providing a robust foundation for their authenticity.\n",
    "\"\"\"\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are a forensic analyst tasked with reinforcing the authenticity of facial images that have already been confirmed as real. Your objective is to methodically analyze each image and provide detailed evidence to support its genuine nature, emphasizing natural characteristics and explaining why these features affirm the image's authenticity. Every aspect of the image must be reviewed thoroughly to strengthen confidence in its real-world origin.\n",
    "\n",
    "Remember: All provided images are verified as real. Your role is not to question their authenticity but to highlight and document specific features or details that unequivocally demonstrate they are genuine.\n",
    "\n",
    "Mandatory Analysis: Use the following five guidelines to validate the authenticity of each image and confirm their real-world origins. If you encounter any additional clues or indicators that reinforce their authenticity, document them thoroughly. Be precise, as the analysis will be critical in affirming these images as genuine.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.56.2-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\douly\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lmm-fvm8fsl0-py3.11\\lib\\site-packages (from openai) (4.6.2.post1)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\douly\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lmm-fvm8fsl0-py3.11\\lib\\site-packages (from openai) (0.24.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.0-cp311-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\douly\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lmm-fvm8fsl0-py3.11\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\douly\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lmm-fvm8fsl0-py3.11\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\douly\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lmm-fvm8fsl0-py3.11\\lib\\site-packages (from openai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\douly\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lmm-fvm8fsl0-py3.11\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\douly\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lmm-fvm8fsl0-py3.11\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\douly\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lmm-fvm8fsl0-py3.11\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in c:\\users\\douly\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lmm-fvm8fsl0-py3.11\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (0.17.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\douly\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lmm-fvm8fsl0-py3.11\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\douly\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lmm-fvm8fsl0-py3.11\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\douly\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lmm-fvm8fsl0-py3.11\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\douly\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lmm-fvm8fsl0-py3.11\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Downloading openai-1.56.2-py3-none-any.whl (389 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.8.0-cp311-none-win_amd64.whl (208 kB)\n",
      "Installing collected packages: jiter, distro, openai\n",
      "Successfully installed distro-1.9.0 jiter-0.8.0 openai-1.56.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image: https://raw.githubusercontent.com/KimEunOh/image/main/wiki/311900_1959-03-29_2010.jpg\n",
      "Response for https://raw.githubusercontent.com/KimEunOh/image/main/wiki/311900_1959-03-29_2010.jpg: **Authenticity Analysis of the Image**\n",
      "\n",
      "1. **Key Facial Features Analysis**\n",
      "   - **Alignment, proportions, and symmetry**: The eyes, nose, and mouth show consistent alignment and natural proportions. The features are symmetrical, with no noticeable discrepancies in placement.\n",
      "   - **Pupil reflection, asymmetry, and shape**: The pupils exhibit natural reflections consistent with the light source, appearing round and symmetric.\n",
      "   - **Unnatural aspects**: Facial features look natural and well-integrated. There are no exaggerated or distorted shapes detected.\n",
      "   - **Awkward lip shape and ambiguous teeth presentation**: The closed lip shape appears natural with no unnatural contours or irregularities.\n",
      "\n",
      "2. **Skin Texture and Tone Analysis**\n",
      "   - **Texture, smoothness, and tone transitions**: The skin texture shows natural variations and realistic transitions between highlights and shadows. There are no overly smooth areas or repetitive patterns indicative of edits.\n",
      "   - **Differences in skin color between the face and neck**: The skin tone is consistent between the face and neck, with no evidence of unnatural color mismatches.\n",
      "\n",
      "3. **Low-Level Detail Inspection**\n",
      "   - **Edges and borders**: The edges around the face are clean and sharp, consistent with natural anatomical boundaries.\n",
      "   - **Sharpness and distortion**: There are no signs of unusual sharpness or distortion in facial features.\n",
      "   - **Reflections and shadows**: Reflections and shadows align with the lighting source. The shadows on the face provide depth and match the overall lighting.\n",
      "   - **Perspective and shape**: The perspective of facial features is logical and consistent with the orientation of the head.\n",
      "   - **Hair texture**: Hair texture appears natural and detailed, with no blurring or overly smooth edges.\n",
      "\n",
      "4. **Lighting, Theme, and Environment Consistency**\n",
      "   - **Lighting and shadow consistency**: The lighting is coherent, with shadows on the face and background matching the light source direction.\n",
      "   - **Theme consistency**: The background and overall theme are consistent with the setting, reflecting a professional environment.\n",
      "\n",
      "5. **Additional Deepfake Clues**\n",
      "   - **Subtle facial expressions and muscle movements**: The facial expression appears natural, capturing authentic muscle movements and subtle expressions.\n",
      "   - **Distortion of wrinkles around the eyes and nose**: Wrinkles and other fine details around the eyes appear natural and undistorted, indicating authentic expression.\n",
      "\n",
      "**Conclusion**: The image's features and environment suggest it is genuine, with no signs of manipulation or inconsistency. The natural alignment, skin texture, lighting, and expression all affirm its authenticity.\n",
      "\n",
      "Response saved for image: https://raw.githubusercontent.com/KimEunOh/image/main/wiki/311900_1959-03-29_2010.jpg\n",
      "\n",
      "Processing image: https://raw.githubusercontent.com/KimEunOh/image/main/wiki/312099_1964-09-11_1999.jpg\n",
      "Response for https://raw.githubusercontent.com/KimEunOh/image/main/wiki/312099_1964-09-11_1999.jpg: **Key Facial Features Analysis**  \n",
      "- The facial features exhibit natural alignment and symmetrical proportions, particularly visible in the even positioning of the eyes, nose, and mouth. The gaze is focused and consistent with the body’s direction.\n",
      "- There is no evidence of gaze inconsistencies or unusual pupil reflections, as the sunglasses obscure direct observation.\n",
      "\n",
      "**Skin Texture and Tone Analysis**  \n",
      "- The skin texture appears natural, with consistent tone and realistic shading across visible areas such as the arms and legs. There are no signs of unnatural smoothness or texture patterns.\n",
      "- The skin tone between the face and neck is consistent, reflective of natural conditions during outdoor activities.\n",
      "\n",
      "**Low-Level Detail Inspection**  \n",
      "- The edges where the cyclist’s body meets the background are naturally defined, with no signs of digital manipulation. The image shows sharpness consistent with motion capture, with some motion blur typical of dynamic photography.\n",
      "- Reflections and shadows are logically consistent, adhering to the outdoor lighting conditions.\n",
      "\n",
      "**Lighting, Theme, and Environment Consistency**  \n",
      "- The lighting on the cyclist is coherent with the shadow and light patterns on the street and nearby objects, consistent with sunlight casting shadows on one side.\n",
      "- The theme and environment blend naturally, with no discrepancies between the athlete’s attire and the setting.\n",
      "\n",
      "**Additional Deepfake Clues**  \n",
      "- The image exhibits natural presentation of motion and muscle tension, indicative of an authentic capture. There are no anomalies in facial expressions or wrinkles observed, although facial details are partially concealed by sunglasses and the helmet.\n",
      "\n",
      "**The Bottom Line**  \n",
      "The photo presents a cyclist with natural facial alignment, consistent skin tone, and logical environmental shadows—supporting its authenticity as a genuine photograph.\n",
      "\n",
      "Response saved for image: https://raw.githubusercontent.com/KimEunOh/image/main/wiki/312099_1964-09-11_1999.jpg\n",
      "\n",
      "Processing image: https://raw.githubusercontent.com/KimEunOh/image/main/wiki/3131650_1984-12-11_2007.jpg\n",
      "Response for https://raw.githubusercontent.com/KimEunOh/image/main/wiki/3131650_1984-12-11_2007.jpg: **1. Key Facial Features Analysis**\n",
      "\n",
      "- **Alignment, proportions, and symmetry**: The alignment of the eyes, nose, mouth, and ears appears natural and symmetrical. The gaze is consistent and directed, with no inconsistencies. Pupil reflections are symmetrical with a natural shape.\n",
      "- **Unnatural aspects**: No exaggerated or distorted features; all facial elements are proportional and appropriately positioned.\n",
      "- **Awkward lip shape and ambiguous teeth presentation**: Lips have a natural contour, with no ambiguity in shape.\n",
      "\n",
      "**2. Skin Texture and Tone Analysis**\n",
      "\n",
      "- **Texture, smoothness, and tone transitions**: The skin shows natural texture and tone variations. There are no overly smooth areas or repetitive patterns indicating manipulation.\n",
      "- **Differences in skin colour between the face and neck**: The skin tone is consistent between the face and neck, with no unnatural lighting or colour mismatches.\n",
      "\n",
      "**3. Low-Level Detail Inspection**\n",
      "\n",
      "- **Edges and borders**: Facial edges with the background are sharp and natural. Edges of facial features blend seamlessly with the surrounding skin.\n",
      "- **Sharpness and distortion**: The image maintains consistent sharpness and lacks any distorted areas.\n",
      "- **Tone and contrast**: Natural tone and contrast are maintained, with no abrupt shading changes.\n",
      "- **Layout and symmetry**: The face has a naturally symmetric layout.\n",
      "- **Reflections and shadows**: Consistent reflections and shadowing align with the external lighting.\n",
      "- **Perspective and shape**: Perspective and shape of features are consistent with the head’s orientation.\n",
      "- **Mismatch between face and body proportions**: Proportions between the face and body are natural.\n",
      "- **Blurry texture of hair at high resolution**: Hair texture is clear and consistent, with no blurriness.\n",
      "\n",
      "**4. Lighting, Theme, and Environment Consistency**\n",
      "\n",
      "- **Lighting and shadow consistency**: Lighting is coherent, with consistent shadows and highlights.\n",
      "- **Theme consistency**: The environment and theme of the image are consistent and harmonized.\n",
      "\n",
      "**5. Additional Deepfake Clues**\n",
      "\n",
      "- **Subtle facial expressions and muscle movements**: Natural muscle movements and facial expressions indicate authenticity.\n",
      "- **Distortion of wrinkles around the eyes and nose**: Natural presentation of wrinkles with consistent movement indicates no manipulation.\n",
      "\n",
      "**Conclusion**: The image shows natural facial features, skin texture, and consistent lighting, reinforcing its authenticity.\n",
      "\n",
      "Response saved for image: https://raw.githubusercontent.com/KimEunOh/image/main/wiki/3131650_1984-12-11_2007.jpg\n",
      "\n",
      "Processing image: https://raw.githubusercontent.com/KimEunOh/image/main/wiki/3132799_1953-05-05_2010.jpg\n",
      "Response for https://raw.githubusercontent.com/KimEunOh/image/main/wiki/3132799_1953-05-05_2010.jpg: **Key Facial Features Analysis**\n",
      "\n",
      "- **Alignment, proportions, and symmetry**: The facial features appear naturally aligned with realistic proportions.\n",
      "- **Gaze consistency**: The eyes gaze in a consistent direction, and there are no signs of gaze inconsistency.\n",
      "- **Pupil reflection**: Light reflections in the eyes are typical, aligning with the light source.\n",
      "- **Unnatural aspects**: There are no observed deformities or distortions in facial features.\n",
      "- **Lip shape and teeth**: The lips appear naturally shaped without awkward contours, and the mouth's closure is clear.\n",
      "\n",
      "**Skin Texture and Tone Analysis**\n",
      "\n",
      "- **Texture, smoothness, and tone transitions**: The skin texture is consistent with natural variation; there are no overly smooth or pixelated areas.\n",
      "- **Differences in skin color between the face and neck**: There is a consistent skin tone between the face and neck, suggesting no manipulation.\n",
      "\n",
      "**Low-Level Detail Inspection**\n",
      "\n",
      "- **Edges and borders**: The transition between the face and the background is smooth, with no artificial blending.\n",
      "- **Sharpness and distortion**: There is natural sharpness without distortion or artificial enhancement.\n",
      "- **Tone and contrast**: Tone and contrast are even and consistent across the face.\n",
      "- **Layout and symmetry**: The face displays natural symmetry with no apparent irregularities.\n",
      "- **Reflections and shadows**: Shadows and lighting are consistent with the light source.\n",
      "- **Perspective and shape**: The facial perspective aligns naturally with the head’s orientation.\n",
      "- **Mismatch between face and body proportions**: The face is proportionate to the body.\n",
      "- **Blurry texture of hair at high resolution**: Hair appears consistent with natural texture, with no blurriness indicating manipulation.\n",
      "\n",
      "**Lighting, Theme, and Environment Consistency**\n",
      "\n",
      "- **Lighting and shadow consistency**: Lighting and shadows are coherent, with no inconsistencies in direction or intensity.\n",
      "- **Theme consistency**: The overall theme, including the stage setup and mood, aligns with the context of a live performance.\n",
      "\n",
      "**Additional Deepfake Clues**\n",
      "\n",
      "- **Subtle facial expressions and muscle movements**: The facial expressions and muscle movements appear natural and fluid.\n",
      "- **Distortion of wrinkles around the eyes and nose**: Wrinkle patterns are consistent with natural expressions, without abnormal distortion.\n",
      "\n",
      "The image presents a genuine capture, evidenced by the natural alignment of facial features, consistent skin tone, coherent lighting, and authentic environmental context.\n",
      "\n",
      "Response saved for image: https://raw.githubusercontent.com/KimEunOh/image/main/wiki/3132799_1953-05-05_2010.jpg\n",
      "Batch 101 processed and saved.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "# GitHub information\n",
    "username = \"KimEunOh\"\n",
    "repo = \"image\"\n",
    "branch = \"main\"\n",
    "folder_path = \"wiki\"\n",
    "\n",
    "# GitHub API to get the list of files in the root directory\n",
    "url = f\"https://api.github.com/repos/{username}/{repo}/contents/{folder_path}?ref={branch}\"\n",
    "response = requests.get(url)\n",
    "files = response.json()\n",
    "\n",
    "# Generate the image URLs\n",
    "image_urls = [\n",
    "    f\"https://raw.githubusercontent.com/{username}/{repo}/{branch}/{folder_path}/{file['name']}\"\n",
    "    for file in files\n",
    "    if file[\"name\"].lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "][:504]\n",
    "\n",
    "# Configuration for batch processing\n",
    "client = OpenAI()\n",
    "batch_size = 5  # Number of images to process per batch\n",
    "output_file = \"wiki.jsonl\"\n",
    "\n",
    "# Function to read already processed URLs from JSONL file\n",
    "def get_processed_urls(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        return set()\n",
    "    \n",
    "    processed_urls = set()\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            for message in data[\"messages\"]:\n",
    "                if message[\"role\"] == \"user\":\n",
    "                    for content in message[\"content\"]:\n",
    "                        if content[\"type\"] == \"image_url\":\n",
    "                            processed_urls.add(content[\"image_url\"][\"url\"])\n",
    "    return processed_urls\n",
    "\n",
    "# Function to process a batch of images\n",
    "def process_batch(batch, jsonl_file):\n",
    "    for image_url in batch:\n",
    "        try:\n",
    "            print(f\"\\nProcessing image: {image_url}\")\n",
    "\n",
    "            # Fetch the image content\n",
    "            image_data = requests.get(image_url, timeout=10).content\n",
    "            image_base64 = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "            image_data_url = f\"data:image/jpeg;base64,{image_base64}\"\n",
    "\n",
    "            # Send request to the OpenAI API\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_message},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": prompt_text},\n",
    "                            {\"type\": \"image_url\", \"image_url\": {\"url\": image_data_url}},\n",
    "                        ],\n",
    "                    },\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            # Extract the response content\n",
    "            response_text = response.choices[0].message.content\n",
    "            print(f\"Response for {image_url}: {response_text}\")\n",
    "\n",
    "            # Create JSONL format data\n",
    "            jsonl_data = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": system_message},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": prompt_text},\n",
    "                            {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "                        ],\n",
    "                    },\n",
    "                    {\"role\": \"assistant\", \"content\": response_text},\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            # Write data to JSONL file\n",
    "            jsonl_file.write(json.dumps(jsonl_data, ensure_ascii=False) + \"\\n\")\n",
    "            print(\"\\nResponse saved for image:\", image_url)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_url}: {e}\")\n",
    "\n",
    "# Main processing logic\n",
    "processed_urls = get_processed_urls(output_file)\n",
    "\n",
    "with open(output_file, \"a\", encoding=\"utf-8\") as jsonl_file:\n",
    "    for i in range(0, len(image_urls), batch_size):\n",
    "        batch = [url for url in image_urls[i : i + batch_size] if url not in processed_urls]\n",
    "        if batch:  # Only process if there are unprocessed URLs\n",
    "            process_batch(batch, jsonl_file)\n",
    "            print(f\"Batch {i // batch_size + 1} processed and saved.\")\n",
    "            time.sleep(2)  # Add delay between batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-sJW5TnaiYCK3kovqfV60YE7k', bytes=89758, created_at=1730790825, filename='output_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "client.files.create(file=open(\"output_data.jsonl\", \"rb\"), purpose=\"fine-tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-WvHRlJkDGe69bHbp2VUXB6f4', created_at=1730790990, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-EufXKKMM6SrUp79tauCwIt84', result_files=[], seed=1353083502, status='validating_files', trained_tokens=None, training_file='file-sJW5TnaiYCK3kovqfV60YE7k', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "    training_file=\"file-sJW5TnaiYCK3kovqfV60YE7k\", model=\"gpt-4o-2024-08-06\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-WvHRlJkDGe69bHbp2VUXB6f4', created_at=1730790990, error=Error(code='invalid_n_examples', message='Training file has 0 example(s), but must have at least 10 examples', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-EufXKKMM6SrUp79tauCwIt84', result_files=[], seed=1353083502, status='failed', trained_tokens=None, training_file='file-sJW5TnaiYCK3kovqfV60YE7k', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None), FineTuningJob(id='ftjob-DxKpjIpD3PYXRuLL04q4mV2U', created_at=1730184962, error=Error(code='invalid_n_examples', message='Training file has 0 example(s), but must have at least 10 examples', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-EufXKKMM6SrUp79tauCwIt84', result_files=[], seed=1391474059, status='failed', trained_tokens=None, training_file='file-aDOpvNK19nMFrw4UPHDqYbRg', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None), FineTuningJob(id='ftjob-8NoRmG75MCZMb7wuWTGvxju1', created_at=1730184815, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Line 1, message 3: \"content\" field must be set with a string or a list of content values.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-EufXKKMM6SrUp79tauCwIt84', result_files=[], seed=1913954623, status='failed', trained_tokens=None, training_file='file-FJxyXs8eErazPEVln3UEIViv', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None), FineTuningJob(id='ftjob-kCvSPRcmi4MKP0SkkCdN4nVQ', created_at=1730184596, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Line 1, message 3: \"content\" field must be set with a string or a list of content values.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-EufXKKMM6SrUp79tauCwIt84', result_files=[], seed=461613003, status='failed', trained_tokens=None, training_file='file-laH3CZvjAJiTsv5x9ILvs9xw', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None), FineTuningJob(id='ftjob-W5hQrcx1QJBLFOg7BPx2wPHQ', created_at=1730183842, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Line 1, message 3: \"content\" field must be set with a string or a list of content values.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-EufXKKMM6SrUp79tauCwIt84', result_files=[], seed=27868403, status='failed', trained_tokens=None, training_file='file-laH3CZvjAJiTsv5x9ILvs9xw', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None), FineTuningJob(id='ftjob-FhTuZMyLT4GgPIqLSXvODqKz', created_at=1730183825, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Line 1, message 3: \"content\" field must be set with a string or a list of content values.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-EufXKKMM6SrUp79tauCwIt84', result_files=[], seed=920934212, status='failed', trained_tokens=None, training_file='file-laH3CZvjAJiTsv5x9ILvs9xw', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)], object='list', has_more=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-7UUEkqSF-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
